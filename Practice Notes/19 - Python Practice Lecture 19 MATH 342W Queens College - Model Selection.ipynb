{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Practice Lecture 19 MATH 342W Queens College\n",
    "# - Model Selection\n",
    "Author: Amir ElTabakh\n",
    "Date: April 14, 2022\n",
    "Agenda:\n",
    "* Model Selection and Three Data Splits\n",
    "* * Use Case (I) Selecting one of $M$ Explicit Models\n",
    "* * Use Case (II) Forward Stepwise Model Construction\n",
    "* * Use Case (III) Hyperparameter Selection **(won't do)**\n",
    "\n",
    "This unit is split into three use cases (1) Selection among M explicit models (2) Hyperparameter Selection within one algorithm (3) Stepwise Model Construction.\n",
    "\n",
    "I won't be doing Hyperparameter tuning, but there is a lot of good stuff on the topic, such as this blog on [Towards Data Science](https://towardsdatascience.com/the-art-of-hyperparameter-tuning-in-python-c581a129d4e4).\n",
    "\n",
    "We have now covered non-linearities (e.g. polynomial terms) and interactions. A new complication now clearly emerges. If I have $p$ predictors, there are many linear least squares models I can build (considering non-linear least squares models makes the space of models even larger!!)\n",
    "\n",
    "## Use Case (I): Selecting one of $M$ Explicit Models\n",
    "\n",
    "We'll be using the diamonds dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Data viz\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_palette(sns.color_palette(\"colorblind\")) # setting color palette\n",
    "sns.set(rc={\"figure.figsize\":(10, 6)}) #width=10, #height=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.86</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.75</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "0       0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1       0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2       0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3       0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4       0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
       "...      ...        ...   ...     ...    ...    ...    ...   ...   ...   ...\n",
       "53935   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75  5.76  3.50\n",
       "53936   0.72       Good     D     SI1   63.1   55.0   2757  5.69  5.75  3.61\n",
       "53937   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66  5.68  3.56\n",
       "53938   0.86    Premium     H     SI2   61.0   58.0   2757  6.15  6.12  3.74\n",
       "53939   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83  5.87  3.64\n",
       "\n",
       "[53940 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# URL for Diamonds Data\n",
    "url = \"https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv\"\n",
    "diamonds = pd.read_csv(url)\n",
    "diamonds = diamonds.iloc[:, 1:]\n",
    "\n",
    "# snapshot of dataframe\n",
    "diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_I1</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  table     x     y     z  cut_Fair  cut_Good  cut_Ideal  \\\n",
       "0   0.23   61.5   55.0  3.95  3.98  2.43         0         0          1   \n",
       "1   0.21   59.8   61.0  3.89  3.84  2.31         0         0          0   \n",
       "2   0.23   56.9   65.0  4.05  4.07  2.31         0         1          0   \n",
       "3   0.29   62.4   58.0  4.20  4.23  2.63         0         0          0   \n",
       "4   0.31   63.3   58.0  4.34  4.35  2.75         0         1          0   \n",
       "\n",
       "   cut_Premium  ...  color_I  color_J  clarity_I1  clarity_IF  clarity_SI1  \\\n",
       "0            0  ...        0        0           0           0            0   \n",
       "1            1  ...        0        0           0           0            1   \n",
       "2            0  ...        0        0           0           0            0   \n",
       "3            1  ...        1        0           0           0            0   \n",
       "4            0  ...        0        1           0           0            0   \n",
       "\n",
       "   clarity_SI2  clarity_VS1  clarity_VS2  clarity_VVS1  clarity_VVS2  \n",
       "0            1            0            0             0             0  \n",
       "1            0            0            0             0             0  \n",
       "2            0            1            0             0             0  \n",
       "3            0            0            1             0             0  \n",
       "4            1            0            0             0             0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets massage our data\n",
    "\n",
    "# defining y\n",
    "y = diamonds['price']\n",
    "\n",
    "# use the Pandas.copy() method to shallow copy\n",
    "X = diamonds.copy()\n",
    "del X['price'] # removing y from X\n",
    "\n",
    "# Dummify Categorical Variables in X\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to conveniently output R^2 and RMSE\n",
    "def solve_performance(model, y, predict_data):        \n",
    "    # get yhat\n",
    "    yhat = model.predict(predict_data)\n",
    "    \n",
    "    # residual error\n",
    "    e = y - yhat\n",
    "    \n",
    "    # variance of y\n",
    "    s_sq_y = np.var(y)\n",
    "\n",
    "    # variance of e\n",
    "    s_sq_e = np.var(e)\n",
    "\n",
    "    # R^2\n",
    "    rsq = (s_sq_y - s_sq_e) / s_sq_y\n",
    "    \n",
    "    # SSE\n",
    "    sse = pd.Series(e**2).sum()\n",
    "\n",
    "    # MSE\n",
    "    mse = sse / len(y)\n",
    "    \n",
    "    # RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # output\n",
    "    print(f\"Rsq: {round(rsq, 5)}\")\n",
    "    print(f\"RMSE: {round(rmse, 5)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsq: 0.85068\n",
      "RMSE: 1541.60631\n",
      "\n",
      "Rsq: 0.87212\n",
      "RMSE: 1426.63891\n",
      "\n",
      "Rsq: 0.91979\n",
      "RMSE: 1129.84299\n",
      "\n",
      "Rsq: 0.91098\n",
      "RMSE: 1190.27771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "model_1 = smf.ols('price ~ carat + depth', data = diamonds).fit()\n",
    "\n",
    "# get performance metrics for model 1\n",
    "solve_performance(model = model_1,\n",
    "               y = diamonds['price'],\n",
    "               predict_data = diamonds[['carat', 'depth']])\n",
    "\n",
    "# model 2\n",
    "model_2 = smf.ols('price ~ carat + depth + color + x + y + z', data = diamonds).fit()\n",
    "\n",
    "# get performance metrics for model 2\n",
    "solve_performance(model = model_2,\n",
    "               y = diamonds['price'],\n",
    "               predict_data = diamonds[['carat',\n",
    "                                        'depth',\n",
    "                                        'color',\n",
    "                                        'x', 'y', 'z']])\n",
    "\n",
    "# model 3\n",
    "# model_3 = smf.ols('price ~ .', data = diamonds) # `.` operator not valid in Python\n",
    "\n",
    "model_3 = LinearRegression().fit(X, y)\n",
    "\n",
    "# get performance metrics for model 3\n",
    "solve_performance(model = model_3,\n",
    "                y = y,\n",
    "                predict_data = X)\n",
    "\n",
    "\n",
    "# model 4\n",
    "model_4 = LinearRegression().fit(X * X, y)\n",
    "\n",
    "# get performance metrics for model 4\n",
    "solve_performance(model = model_4,\n",
    "                y = y,\n",
    "                predict_data = X*X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously the in-sample $R^2$'s are increasing due to the complexity, but which model is \"best\"?\n",
    "\n",
    "This is one of the most fundamental problems in statistics, and possibly all of science! \n",
    "\n",
    "In class, we discussed validation via dividing $\\mathbb{D}$ into (a) a training set and a (b) testing set. Now, we will further divide the training set into (a) a sub-training set and a (b) selection set and we still have the (c) test set. \n",
    "\n",
    "The total training set together will fit a model and testing will estimate future performance. But within the total training set, we'll use an elaborate algorithim: we'll fit many models and take the best one. That's the \"master algorithm\".\n",
    "\n",
    "We'll make the selection set and the test set the same size but we don't have to. First split up the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53940\n",
      "53940\n"
     ]
    }
   ],
   "source": [
    "# setting constants\n",
    "random.seed(2000)\n",
    "n = len(diamonds)\n",
    "K = 10\n",
    "prop_train = (K - 1) / K\n",
    "n_train_master = int(prop_train * n)\n",
    "\n",
    "# setting indices\n",
    "indices = set([i for i in range(n)])\n",
    "index_master_train = set(random.sample(indices, n_train_master))\n",
    "index_select = indices - index_master_train\n",
    "\n",
    "# Now we have a master_train and select\n",
    "# We'll split the master_train into train and test now\n",
    "n_train = int(prop_train * n_train_master)\n",
    "index_train = set(random.sample(index_master_train, n_train))\n",
    "index_test = index_master_train - index_train\n",
    "\n",
    "# check\n",
    "print(len(diamonds))\n",
    "print(len(index_test) + len(index_train) + len(index_select))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our indices, lets create the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split based on indices\n",
    "X_train = pd.DataFrame([X.iloc[i] for i in index_train])\n",
    "y_train = pd.Series([y[i] for i in index_train])\n",
    "\n",
    "X_test = pd.DataFrame([X.iloc[i] for i in index_test])\n",
    "y_test = pd.Series([y[i] for i in index_test])\n",
    "\n",
    "X_select = pd.DataFrame([X.iloc[i] for i in index_select])\n",
    "y_select = pd.Series([y[i] for i in index_select])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit all models on the training set, get **in sample** performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsq: 0.85069\n",
      "RMSE: 1542.33733\n",
      "\n",
      "Rsq: 0.87286\n",
      "RMSE: 1423.2295\n",
      "\n",
      "Rsq: 0.92006\n",
      "RMSE: 1128.54461\n",
      "\n",
      "Rsq: 0.91162\n",
      "RMSE: 1186.58528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "X_train_1 = X_train[['carat', 'depth']]\n",
    "model_1 = LinearRegression().fit(X_train_1, y_train)\n",
    "\n",
    "# get in sample performance metrics for model 1\n",
    "solve_performance(model = model_1,\n",
    "               y = y_train,\n",
    "               predict_data = X_train_1)\n",
    "\n",
    "# model 2\n",
    "X_train_2 = X_train[['carat',\n",
    "                    'depth',\n",
    "                    'color_D', 'color_E', 'color_F', 'color_G',\n",
    "                    'color_H', 'color_I', 'color_J',\n",
    "                    'x', 'y', 'z']]\n",
    "\n",
    "model_2 = LinearRegression().fit(X_train_2, y_train)\n",
    "\n",
    "# get in sample performance metrics for model 2\n",
    "solve_performance(model = model_2,\n",
    "               y = y_train,\n",
    "               predict_data = X_train_2)\n",
    "\n",
    "# model 3\n",
    "model_3 = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# get in sample performance metrics for model 3\n",
    "solve_performance(model = model_3,\n",
    "                y = y_train,\n",
    "                predict_data = X_train)\n",
    "\n",
    "\n",
    "# model 4\n",
    "model_4 = LinearRegression().fit(X_train * X_train, y_train)\n",
    "\n",
    "# get in sample performance metrics for model 4\n",
    "solve_performance(model = model_4,\n",
    "                y = y_train,\n",
    "                predict_data = X_train * X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fit all models on the training set, get **out of sample** performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsq: 0.85672\n",
      "RMSE: 1537.21615\n",
      "\n",
      "Rsq: 0.88179\n",
      "RMSE: 1396.5831\n",
      "\n",
      "Rsq: 0.92437\n",
      "RMSE: 1116.95235\n",
      "\n",
      "Rsq: 0.89978\n",
      "RMSE: 1285.62896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "X_train_1 = X_train[['carat', 'depth']]\n",
    "model_1 = LinearRegression().fit(X_train_1, y_train)\n",
    "\n",
    "# get oos performance metrics for model 1\n",
    "X_test_1 = X_test[['carat', 'depth']]\n",
    "\n",
    "solve_performance(model = model_1,\n",
    "               y = y_test,\n",
    "               predict_data = X_test_1)\n",
    "\n",
    "\n",
    "# model 2\n",
    "X_train_2 = X_train[['carat',\n",
    "                    'depth',\n",
    "                    'color_D', 'color_E', 'color_F', 'color_G',\n",
    "                    'color_H', 'color_I', 'color_J',\n",
    "                    'x', 'y', 'z']]\n",
    "\n",
    "model_2 = LinearRegression().fit(X_train_2, y_train)\n",
    "\n",
    "# get oos performance metrics for model 2\n",
    "X_test_2 = X_test[['carat',\n",
    "                    'depth',\n",
    "                    'color_D', 'color_E', 'color_F', 'color_G',\n",
    "                    'color_H', 'color_I', 'color_J',\n",
    "                    'x', 'y', 'z']]\n",
    "\n",
    "solve_performance(model = model_2,\n",
    "               y = y_test,\n",
    "               predict_data = X_test_2)\n",
    "\n",
    "\n",
    "# model 3\n",
    "model_3 = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# get oos performance metrics for model 3\n",
    "solve_performance(model = model_3,\n",
    "                y = y_test,\n",
    "                predict_data = X_test)\n",
    "\n",
    "\n",
    "# model 4\n",
    "model_4 = LinearRegression().fit(X_train * X_train, y_train)\n",
    "\n",
    "# get oos performance metrics for model 4\n",
    "solve_performance(model = model_4,\n",
    "                y = y_test,\n",
    "                predict_data = X_test * X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which are overfit? Which are underfit? Were these models \"poor choices\"? Can we go back and fit some more models? \n",
    "\n",
    "Yes - as long as we don't open the \"lockbox\" of the test set. We can go further and fit more and more models but we should always be careful that we don't fit too many as we may optimize to the selection set. Here, we are lucky since the selection set is large (~11,000 observations) so this is not too much of a fear.\n",
    "\n",
    "But you can see the problem - how can we build a good model?\n",
    "\n",
    "The answer to this is non-parametric regression / machine learning. But first, we will cover two other important topics before we get there.\n",
    "\n",
    "Let us return and complete the exercise by now declaring we are done modeling and we are going to ship model 3. Now that we know we're using Model 3, lets append `X_train` and `X_test` and now we will use `X_select` as the test set. Let us get a conservative estimate of its performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsq: 0.91245\n",
      "RMSE: 1156.23815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining master train\n",
    "X_train_master = pd.DataFrame([X.iloc[i] for i in index_master_train])\n",
    "y_train_master = pd.Series([y[i] for i in index_master_train])\n",
    "\n",
    "# fitting model 3\n",
    "model_3 = LinearRegression().fit(X_train_master, y_train_master)\n",
    "\n",
    "# get oos *select* performance metrics for model 3\n",
    "solve_performance(model = model_3,\n",
    "                y = y_select,\n",
    "                predict_data = X_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test and select sets seem to perform about the same. We did not overfit too much on the select set. At this point the lockbox is open and we can never return (if we are honest, of course - many people in this business lie so beware).\n",
    "\n",
    "This is the model we will ship to production!\n",
    "\n",
    "Two improvements using CV to the above:\n",
    "\n",
    "* To reduce variance in the selection process, you make a CV of the selection set. \n",
    "* To reduce variance in the testing process, you make an outer CV of the test set. This is a lot more coding! (good lab question)\n",
    "\n",
    "Professor Kapelner uses the R MLR package to show off this process. I don't know if such a library exists in Python. You could use the SKLearn's train test split function twice to get your train, test and select datasets.\n",
    "\n",
    "SKLearn has a bunch of splitter classes, [check them out](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection).\n",
    "\n",
    "## Use Case (II): Forward Stepwise Model Construction\n",
    "\n",
    "There are many types of such stepwise models. Here we will look at Forward Stepwise Linear models. \"Forward\" meaning we start with a low complexity model and end with a high complexity model, \"Stepwise\" meaning we do so iteratively which each step consisting of one additional degree of freedom i.e. one incremental increase in complexity and \"Linear\" meaning that the model is linear. By default we use OLS.\n",
    "\n",
    "We will be using the diamonds data again as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53935</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.86</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.75</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "0       0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1       0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2       0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3       0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4       0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
       "...      ...        ...   ...     ...    ...    ...    ...   ...   ...   ...\n",
       "53935   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75  5.76  3.50\n",
       "53936   0.72       Good     D     SI1   63.1   55.0   2757  5.69  5.75  3.61\n",
       "53937   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66  5.68  3.56\n",
       "53938   0.86    Premium     H     SI2   61.0   58.0   2757  6.15  6.12  3.74\n",
       "53939   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83  5.87  3.64\n",
       "\n",
       "[53940 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# snapshot\n",
    "diamonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're doing will be highly computational, so let's take a small random sample of the dimaonds in $\\mathbb{D}$ for training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22208</th>\n",
       "      <td>1.21</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>60.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10256</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.89</td>\n",
       "      <td>4.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13027</th>\n",
       "      <td>0.26</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>600</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.04</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23817</th>\n",
       "      <td>1.22</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.7</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11880</td>\n",
       "      <td>6.79</td>\n",
       "      <td>6.84</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22147</th>\n",
       "      <td>2.01</td>\n",
       "      <td>Good</td>\n",
       "      <td>I</td>\n",
       "      <td>SI1</td>\n",
       "      <td>64.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10184</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.88</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8172</th>\n",
       "      <td>1.05</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4363</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.49</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18025</th>\n",
       "      <td>1.50</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7291</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.21</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35600</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>61.6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>907</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17402</th>\n",
       "      <td>1.09</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6970</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.64</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34200</th>\n",
       "      <td>0.33</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>61.9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>854</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31822</th>\n",
       "      <td>0.40</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>775</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.64</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat      cut color clarity  depth  table  price     x     y     z\n",
       "22208   1.21    Ideal     G    VVS2   60.6   56.0  10256  6.90  6.89  4.18\n",
       "13027   0.26  Premium     H    VVS2   62.4   58.0    600  4.07  4.04  2.53\n",
       "23817   1.22    Ideal     F    VVS2   62.7   54.0  11880  6.79  6.84  4.27\n",
       "22147   2.01     Good     I     SI1   64.1   60.0  10184  7.92  7.88  5.06\n",
       "8172    1.05  Premium     F     SI2   61.7   60.0   4363  6.58  6.49  4.03\n",
       "...      ...      ...   ...     ...    ...    ...    ...   ...   ...   ...\n",
       "18025   1.50  Premium     H     SI2   62.3   59.0   7291  7.27  7.21  4.52\n",
       "35600   0.31    Ideal     H    VVS1   61.6   55.0    907  4.38  4.35  2.69\n",
       "17402   1.09    Ideal     H     SI1   61.4   56.0   6970  6.61  6.64  4.07\n",
       "34200   0.33    Ideal     F     VS2   61.9   57.0    854  4.42  4.40  2.73\n",
       "31822   0.40     Good     D     SI2   64.0   56.0    775  4.70  4.64  2.99\n",
       "\n",
       "[1300 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# constants\n",
    "samp_size_train = 1000\n",
    "samp_size_test = 300\n",
    "samp_size = samp_size_train + samp_size_test\n",
    "\n",
    "# take a sample of df\n",
    "diamonds_sample = diamonds.sample(n = samp_size, random_state = 1001)\n",
    "\n",
    "diamonds_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22208</td>\n",
       "      <td>1.21</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>G</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>60.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>10256</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.89</td>\n",
       "      <td>4.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13027</td>\n",
       "      <td>0.26</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>600</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.04</td>\n",
       "      <td>2.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23817</td>\n",
       "      <td>1.22</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>62.7</td>\n",
       "      <td>54.0</td>\n",
       "      <td>11880</td>\n",
       "      <td>6.79</td>\n",
       "      <td>6.84</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22147</td>\n",
       "      <td>2.01</td>\n",
       "      <td>Good</td>\n",
       "      <td>I</td>\n",
       "      <td>SI1</td>\n",
       "      <td>64.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10184</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.88</td>\n",
       "      <td>5.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8172</td>\n",
       "      <td>1.05</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4363</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.49</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>18025</td>\n",
       "      <td>1.50</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7291</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.21</td>\n",
       "      <td>4.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>35600</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>VVS1</td>\n",
       "      <td>61.6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>907</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>17402</td>\n",
       "      <td>1.09</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6970</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.64</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>34200</td>\n",
       "      <td>0.33</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>61.9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>854</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>31822</td>\n",
       "      <td>0.40</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>775</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.64</td>\n",
       "      <td>2.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0     22208   1.21    Ideal     G    VVS2   60.6   56.0  10256  6.90  6.89   \n",
       "1     13027   0.26  Premium     H    VVS2   62.4   58.0    600  4.07  4.04   \n",
       "2     23817   1.22    Ideal     F    VVS2   62.7   54.0  11880  6.79  6.84   \n",
       "3     22147   2.01     Good     I     SI1   64.1   60.0  10184  7.92  7.88   \n",
       "4      8172   1.05  Premium     F     SI2   61.7   60.0   4363  6.58  6.49   \n",
       "...     ...    ...      ...   ...     ...    ...    ...    ...   ...   ...   \n",
       "1295  18025   1.50  Premium     H     SI2   62.3   59.0   7291  7.27  7.21   \n",
       "1296  35600   0.31    Ideal     H    VVS1   61.6   55.0    907  4.38  4.35   \n",
       "1297  17402   1.09    Ideal     H     SI1   61.4   56.0   6970  6.61  6.64   \n",
       "1298  34200   0.33    Ideal     F     VS2   61.9   57.0    854  4.42  4.40   \n",
       "1299  31822   0.40     Good     D     SI2   64.0   56.0    775  4.70  4.64   \n",
       "\n",
       "         z  \n",
       "0     4.18  \n",
       "1     2.53  \n",
       "2     4.27  \n",
       "3     5.06  \n",
       "4     4.03  \n",
       "...    ...  \n",
       "1295  4.52  \n",
       "1296  2.69  \n",
       "1297  4.07  \n",
       "1298  2.73  \n",
       "1299  2.99  \n",
       "\n",
       "[1300 rows x 11 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds_sample = diamonds_sample.reset_index()\n",
    "diamonds_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our $X$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>...</th>\n",
       "      <th>color_I</th>\n",
       "      <th>color_J</th>\n",
       "      <th>clarity_I1</th>\n",
       "      <th>clarity_IF</th>\n",
       "      <th>clarity_SI1</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22208</td>\n",
       "      <td>1.21</td>\n",
       "      <td>60.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.89</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13027</td>\n",
       "      <td>0.26</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.07</td>\n",
       "      <td>4.04</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23817</td>\n",
       "      <td>1.22</td>\n",
       "      <td>62.7</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.79</td>\n",
       "      <td>6.84</td>\n",
       "      <td>4.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22147</td>\n",
       "      <td>2.01</td>\n",
       "      <td>64.1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>7.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8172</td>\n",
       "      <td>1.05</td>\n",
       "      <td>61.7</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.58</td>\n",
       "      <td>6.49</td>\n",
       "      <td>4.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>18025</td>\n",
       "      <td>1.50</td>\n",
       "      <td>62.3</td>\n",
       "      <td>59.0</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.21</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>35600</td>\n",
       "      <td>0.31</td>\n",
       "      <td>61.6</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>17402</td>\n",
       "      <td>1.09</td>\n",
       "      <td>61.4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.64</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>34200</td>\n",
       "      <td>0.33</td>\n",
       "      <td>61.9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>31822</td>\n",
       "      <td>0.40</td>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>4.64</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  carat  depth  table     x     y     z  cut_Fair  cut_Good  \\\n",
       "0     22208   1.21   60.6   56.0  6.90  6.89  4.18         0         0   \n",
       "1     13027   0.26   62.4   58.0  4.07  4.04  2.53         0         0   \n",
       "2     23817   1.22   62.7   54.0  6.79  6.84  4.27         0         0   \n",
       "3     22147   2.01   64.1   60.0  7.92  7.88  5.06         0         1   \n",
       "4      8172   1.05   61.7   60.0  6.58  6.49  4.03         0         0   \n",
       "...     ...    ...    ...    ...   ...   ...   ...       ...       ...   \n",
       "1295  18025   1.50   62.3   59.0  7.27  7.21  4.52         0         0   \n",
       "1296  35600   0.31   61.6   55.0  4.38  4.35  2.69         0         0   \n",
       "1297  17402   1.09   61.4   56.0  6.61  6.64  4.07         0         0   \n",
       "1298  34200   0.33   61.9   57.0  4.42  4.40  2.73         0         0   \n",
       "1299  31822   0.40   64.0   56.0  4.70  4.64  2.99         0         1   \n",
       "\n",
       "      cut_Ideal  ...  color_I  color_J  clarity_I1  clarity_IF  clarity_SI1  \\\n",
       "0             1  ...        0        0           0           0            0   \n",
       "1             0  ...        0        0           0           0            0   \n",
       "2             1  ...        0        0           0           0            0   \n",
       "3             0  ...        1        0           0           0            1   \n",
       "4             0  ...        0        0           0           0            0   \n",
       "...         ...  ...      ...      ...         ...         ...          ...   \n",
       "1295          0  ...        0        0           0           0            0   \n",
       "1296          1  ...        0        0           0           0            0   \n",
       "1297          1  ...        0        0           0           0            1   \n",
       "1298          1  ...        0        0           0           0            0   \n",
       "1299          0  ...        0        0           0           0            0   \n",
       "\n",
       "      clarity_SI2  clarity_VS1  clarity_VS2  clarity_VVS1  clarity_VVS2  \n",
       "0               0            0            0             0             1  \n",
       "1               0            0            0             0             1  \n",
       "2               0            0            0             0             1  \n",
       "3               0            0            0             0             0  \n",
       "4               1            0            0             0             0  \n",
       "...           ...          ...          ...           ...           ...  \n",
       "1295            1            0            0             0             0  \n",
       "1296            0            0            0             1             0  \n",
       "1297            0            0            0             0             0  \n",
       "1298            0            0            1             0             0  \n",
       "1299            1            0            0             0             0  \n",
       "\n",
       "[1300 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining y\n",
    "y = diamonds_sample['price']\n",
    "\n",
    "# use the Pandas.copy() method to shallow copy\n",
    "X = diamonds_sample.copy()\n",
    "del X['price'] # removing y from X\n",
    "\n",
    "# Dummify Categorical Variables in X\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The data is looking good. Let's built a model with all first-order interactions. You can solve for second order interactions by changing the parameter of the `PolynomialFeatures` function from a 2 to a 3. Leave it at 2, or else it will take hours for the models to fit later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "X = pd.DataFrame(poly.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train-test-split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting constants\n",
    "random.seed(2000)\n",
    "n = len(diamonds_sample)\n",
    "K = 5\n",
    "prop_train = (K - 1) / K\n",
    "n_train = int(prop_train * n)\n",
    "\n",
    "# setting indices\n",
    "indices = set([i for i in range(n)]) # good thing we reset the index\n",
    "index_train = set(random.sample(indices, n_train))\n",
    "index_test = indices - index_train\n",
    "\n",
    "# split based on indices\n",
    "X_train = pd.DataFrame([X.iloc[i] for i in index_train])\n",
    "y_train = pd.Series([y[i] for i in index_train])\n",
    "\n",
    "X_test = pd.DataFrame([X.iloc[i] for i in index_test])\n",
    "y_test = pd.Series([y[i] for i in index_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsq: 0.99024\n",
      "RMSE: 390.50235\n",
      "\n",
      "Rsq: -0.26194\n",
      "RMSE: 4583.85271\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# constructing model\n",
    "model_X_poly = LinearRegression(fit_intercept = False).fit(X_train, y_train)\n",
    "\n",
    "# in sample\n",
    "solve_performance(model = model_X_poly,\n",
    "               y = y_train,\n",
    "               predict_data = X_train)\n",
    "\n",
    "# oos\n",
    "solve_performance(model = model_X_poly,\n",
    "               y = y_test,\n",
    "               predict_data = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VERY negative oos $R^2$ --- why? What should that say about the relationship between $s_e$ and $s_y$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4084.4501901778594\n",
      "1.1233599219076231\n"
     ]
    }
   ],
   "source": [
    "# errors for test set\n",
    "y_hat_test = model_X_poly.predict(X_test)\n",
    "e_test = y_test - y_hat_test\n",
    "\n",
    "print(y_test.std())\n",
    "print(e_test.std() / y_test.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not only \"overfitting\"; it is an absolute trainwreck! This means you can do better using the null model (average of y) instead of this model.\n",
    "\n",
    "So let us employ stepwise to get a \"good\" model. We need our basis predictors to start with. How about the linear components of the first order interactions of X --- there's nothing intrinsically wrong with that - it's probably a good basis for $f(x)$. \n",
    "\n",
    "Now let's go through one by one and add the best one based on $s_e$ gain i.e. the best new dimension to add to project the most of the vector $y$ as possible onto the column space.\n",
    "\n",
    "Procedure:\n",
    "1. Start with $p = 1$ features\n",
    "2. Fit model\n",
    "3. Calculate in sample and out of sample metrics and store them in lists\n",
    "4. Add a column to the data set and repeat steps 2, 3, 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to conveniently solve for RMSE\n",
    "def solve_RMSE(model, y, predict_data):        \n",
    "    # get yhat\n",
    "    yhat = model.predict(predict_data)\n",
    "    \n",
    "    # residual error\n",
    "    e = y - yhat\n",
    "    \n",
    "    # variance of y\n",
    "    s_sq_y = np.var(y)\n",
    "\n",
    "    # variance of e\n",
    "    s_sq_e = np.var(e)\n",
    "    \n",
    "    # SSE\n",
    "    sse = pd.Series(e**2).sum()\n",
    "\n",
    "    # MSE\n",
    "    mse = sse / len(y)\n",
    "    \n",
    "    # RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    # output\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Forward Stepwise Procedure\n",
    "in_sample_rmse_by_iteration = [] #keep a growing list of se's by iteration\n",
    "oos_rmse_by_iteration = [] #keep a growing list of se's by iteration\n",
    "\n",
    "for i in range(len(X.columns)):\n",
    "    # Tracker\n",
    "    #print(f\"Index {i} out of {len(X.columns)}\")\n",
    "    \n",
    "    # skip the null model\n",
    "    if i == 0:\n",
    "        continue\n",
    "    \n",
    "    # Define Dataset    \n",
    "    X_p = X.iloc[:, :i]\n",
    "    \n",
    "    # setting constants\n",
    "    random.seed(2000)\n",
    "    n = len(diamonds_sample)\n",
    "    K = 5\n",
    "    prop_train = (K - 1) / K\n",
    "    n_train = int(prop_train * n)\n",
    "\n",
    "    # setting indices\n",
    "    indices = set([i for i in range(n)]) # good thing we reset the index\n",
    "    index_train = set(random.sample(indices, n_train))\n",
    "    index_test = indices - index_train\n",
    "\n",
    "    # split based on indices\n",
    "    X_train = pd.DataFrame([X_p.iloc[i] for i in index_train])\n",
    "    y_train = pd.Series([y[i] for i in index_train])\n",
    "\n",
    "    X_test = pd.DataFrame([X_p.iloc[i] for i in index_test])\n",
    "    y_test = pd.Series([y[i] for i in index_test])\n",
    "    \n",
    "    # constructing model\n",
    "    model_X_p = LinearRegression(fit_intercept = False).fit(X_train, y_train)\n",
    "    \n",
    "    # getting in sample RMSE\n",
    "    in_sample_rmse = solve_RMSE(model = model_X_p,\n",
    "                                y = y_train,\n",
    "                                predict_data = X_train)\n",
    "    \n",
    "    # getting OOS RMSE\n",
    "    oos_sample_rmse = solve_RMSE(model = model_X_p,\n",
    "                                 y = y_test,\n",
    "                                 predict_data = X_test)\n",
    "    \n",
    "    # Adding results to list\n",
    "    in_sample_rmse_by_iteration += [in_sample_rmse]\n",
    "    oos_rmse_by_iteration += [oos_sample_rmse]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at our complexity curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFoCAYAAAD5O+daAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABeO0lEQVR4nO3de5xVdb3/8dda+zb3GWaYARwR8pIkKJiYojaoxwAF0lDLS1rHUyaVlp1jKRLmrzqSkZQnMU+ZnaPdyEyUg6OVSRlWQnlBsUy5DjgMc7/u21q/P9bee/ae2cBc9p49w3o/Hw8eM7P27fudPcBnPp/v9/M1bNu2EREREZGcMXM9ABERERG3U0AmIiIikmMKyERERERyTAGZiIiISI4pIBMRERHJMQVkIiIiIjmmgExEREQkx7y5HsBwNTd3YlnZbaVWUVFEY2NHVl9jNHLrvEFz19zdx61zd+u8QXMf6bmbpsG4cYUHvX3MB2SWZWc9IIu/jhu5dd6gubuV5u4+bp03aO6jiUqWIiIiIjmmgExEREQkxxSQiYiIiOSYAjIRERGRHFNAJiIiIpJjCshEREREckwBmYiIiEiOKSATERERyTEFZCIiIiI5poBMREREJMcUkImIiIjkmAIyERERt4pGKfrcp/G8sS3XI3E9BWQiIiIuZb6zj/yfPoLv+Y25HorrKSATERFxKaO93fkYjeZ4JKKATERExKWMDicgI2rldiCigExERMStjI4O55NIJLcDEQVkIiIibhUPyAxLJctcU0AmIiLiUr0lSwVkuaaATERExKUSAZlKljmngExERMSlzPgaMpUsc04BmYiIiEsl1pBpl2XOKSATERFxKZUsRw8FZCIiIi6VaHuhRf05p4BMRETEpeKd+rWGLPcUkImIiLhU7xoyBWS55s31AERERGRk+Z57Fv6xFaMzvoZMAVmuKSATERFxmbIPXwKAccK7nQsqWeacSpYiIiIu5dm10/lEJcucU0AmIiLiMtGqCQAYwaDzUW0vck4BmYiIiMtY1dWpF5QhyzkFZCIiIi5jVU/uc0EBWa4pIBMREXEZu7Aw5WtDuyxzTgGZiIiI29h26tcqWeacAjIRERG3sfocJq6SZc4pIBMREXGbvhky7bLMOQVkIiIibpMUkNkej45OGgXUqV9ERMRtbKdkaY0fj1VaBlHr0PeXrFOGTERExG1sG979bhpffxuragJEVbLMNQVkIiIibmMDZiwEUMlyVFBAJiIi4jKGZYFhOF+YHrW9GAUUkImIiLiNbfcGZF6PSpajwIACso6ODhYtWsSePXsA2LRpE4sXL2bevHmsXr06cb9t27axZMkS5s+fz+23304kto127969XH311SxYsIClS5fS2dkJQFtbG9dffz0XXnghV199NQ0NDZmen4iIiPRl24mSpe3xaFH/KHDYgOzll1/myiuvZMeOHQD09PSwbNky1qxZw4YNG9i6dSsbN24E4JZbbmHFihU8/fTT2LbN2rVrAbjzzju56qqrqK2tZcaMGaxZswaAb3/728yePZunnnqKyy+/nK9//etZmqaIiIgkJJcstYZsVDhsQLZ27VruuOMOqqqqAHjllVeYMmUKkydPxuv1snjxYmpra6mrq6Onp4dZs2YBsGTJEmprawmHw7z44ovMnz8/5TrAc889x+LFiwFYtGgRv//97wmHw9mYp4iIiMQllyw9XpUsR4HD9iHrm7Xav38/lZWVia+rqqqor6/vd72yspL6+nqam5spKirC6/WmXO/7XF6vl6KiIpqampgwYcLwZyYiIiIH0bdkqQxZrg26MaxlWRjxqBqwbRvDMA56Pf4xWd+vkx9jmoPbZ1BRUTSo+w9VZWXxiLzOaOPWeYPm7laau/u4ct5eEwzDmXtBALBd930YbfMddEA2ceLElMX3DQ0NVFVV9bt+4MABqqqqKC8vp729nWg0isfjSdwfnOzagQMHmDhxIpFIhM7OTsrKygY1nsbGDizLPvwdh6GyspiGhvasvsZo5NZ5g+auubuPW+fu1nmXBMMEDIOGhnaKIza+YJgmF30fcvG+m6ZxyCTSoNtezJw5k+3bt7Nz506i0Sjr16+npqaG6upqAoEAW7ZsAWDdunXU1NTg8/mYPXs2GzZsAODxxx+npqYGgLlz5/L4448DsGHDBmbPno3P5xvskERERGQwknZZ4vGApZJlrg06QxYIBFi5ciU33ngjwWCQuXPnsmDBAgBWrVrF8uXL6ejoYPr06Vx77bUA3HHHHdx6663cf//9TJo0iXvuuQeAz33uc9x6660sXLiQ4uJiVq1alcGpiYiISDrJjWG1hmx0GHBA9uyzzyY+nzNnDk888US/+0ybNo1HH3203/Xq6moefvjhftfLysr43ve+N9AhiIiISCb02WVpRLTLMtfUqV9ERMRtUkqWpkqWo4ACMhEREbex7JTGsCpZ5p4CMhEREbdJKlnaXq+OThoFFJCJiIi4TlLJ0vRgqFN/zikgExERcZs+Z1mqZJl7CshERETcpl/JUgFZrikgExERcZvkXZamqbYXo4ACMhEREZcx+pYswSljSs4oIBMREXGb5Maw3liPeJUtc0oBmYiIiNsklSzteIZMZcucUkAmIiLiNsklSzMWkClDllMKyERERFwnuWTpBGSGjk/KKQVkIiIibpNylqVKlqOBAjIRERG3SSpZ2omSpXZZ5pICMhEREbex6df2QiXL3FJAJiIi4jbJJct42wuVLHNKAZmIiIjbJJcsPdplORooIBMREXEZI7kxbDxTpoAspxSQiYiIuE2akqWhgCynFJCJiIi4jZ3mLEsFZDmlgExERMRtkkqWWkM2OiggExERcZuUxrDxkqV2WeaSAjIRERG3sVSyHG0UkImIiLhN8i5Lj3ZZjgYKyERERNwmZQ1ZvDGsArJcUkAmIiLiNpbV73BxHZ2UWwrIREREXCalMazWkI0KCshERETcJm3JUrssc0kBmYiIiNvYJJUsYx9VsswpBWQiIiJuk6ZTv45Oyi0FZCIiIm6TvIYsdpYlUSt34xEFZCIiIq6T1KnfNmOL+rWGLKcUkImIiLhNuk79WkOWUwrIRERE3CZNyVJryHJLAZmIiIjbpBwuHvuokmVOKSATERFxGSOpZJlYQ6YMWU4pIBMREXGbdCVLS7ssc0kBmYiIiOvY/c6yVMkytxSQiYiIuI1KlqOOAjIRERG3SdcYVm0vckoBmYiIiNuk2WVpqGSZUwrIRERE3May+zeG1dFJOaWATERExG2SSpa2J36WpUqWuaSATERExG3s/rssjahKlrmkgExERMRljHRnWSpDllMKyERERFwn3RoyBWS5NKyAbN26dSxcuJCFCxfyjW98A4BNmzaxePFi5s2bx+rVqxP33bZtG0uWLGH+/PncfvvtRGK7Ofbu3cvVV1/NggULWLp0KZ2dncMZkoiIiBxOcsnSMLBNE1SyzKkhB2Td3d18/etf5+GHH2bdunVs3ryZZ599lmXLlrFmzRo2bNjA1q1b2bhxIwC33HILK1as4Omnn8a2bdauXQvAnXfeyVVXXUVtbS0zZsxgzZo1mZmZiIiIpJdcsgTweDC0yzKnhhyQRaNRLMuiu7ubSCRCJBKhqKiIKVOmMHnyZLxeL4sXL6a2tpa6ujp6enqYNWsWAEuWLKG2tpZwOMyLL77I/PnzU66LiIhIFiU3hgWnbKmSZU55h/rAoqIiPve5z3HhhReSn5/P6aefzv79+6msrEzcp6qqivr6+n7XKysrqa+vp7m5maKiIryxLsHx6yIiIpJFySVLYq0v0jWGDYcxOjuwy8aN4ODcacgB2RtvvMEvf/lLfve731FcXMx//Md/sGPHDoykiNu2bQzDwLKstNfjH5P1/fpwKiqKhjqFQamsLB6R1xlt3Dpv0NzdSnN3H1fOO1ayTMzd66Eg4KGg7/fiK1+Bhx6CnTtHfIjZNtre9yEHZM8//zxz5syhoqICcMqNDz74IJ74bg2goaGBqqoqJk6cSENDQ+L6gQMHqKqqory8nPb2dqLRKB6PJ3H/wWhs7MCy7KFOY0AqK4tpaGjP6muMRm6dN2jumrv7uHXubp33+FhCJD73CtMk2NFNR5/vRemzz+HftYuGvU3g8+ViqFmRi/fdNI1DJpGGvIZs2rRpbNq0ia6uLmzb5tlnn2XmzJls376dnTt3Eo1GWb9+PTU1NVRXVxMIBNiyZQvg7M6sqanB5/Mxe/ZsNmzYAMDjjz9OTU3NUIckIiIiA9GnZInHC5Fov/t4X30ZAKOlZeTG5lJDzpCdc845vP766yxZsgSfz8fJJ5/MjTfeyNlnn82NN95IMBhk7ty5LFiwAIBVq1axfPlyOjo6mD59Otdeey0Ad9xxB7feeiv3338/kyZN4p577snMzERERCQto8+iftvjASs1IDPr9mDGAjGzpZlo0lpwybwhB2QA119/Pddff33KtTlz5vDEE0/0u++0adN49NFH+12vrq7m4YcfHs4wREREZKDs2DKfw+yy9G59NfG50dw8EiNzNXXqFxERcZN4QJZcsvR6MZICMqO+Hu9LWxJfmy1NIzU61xpWhkxERETGGCvWADY5Q2aa5K39KebeOtoeeIiK952C0d2NnZ+P0d2tDNkIUIZMRETETdKULM09uwHwP/97Cr77bYzubiInTqPniqud21sUkGWbMmQiIiJukqZkaSQ1hc3//v1EJ0yk+fd/Btsm70cPKkM2ApQhExERcZM0Jcv21d+l9aEfEz5tNkYkQuj8C5zbTRO7rEwZshGgDJmIiIibpClZ9lzttKLy/PMf+LZsJnTBvMRtVtk4DAVkWaeATERExE3S7bKM6bn6Y5htbYQ+sKD37mVlmCpZZp0CMhERETdJt8syxh4/ns4v35l6TRmyEaE1ZCIiIi5ikKYx7CFY48YpQzYCFJCJiIi4ySFKlmnvXjYOo7Ule+MRQAGZiIiIuxyiZJn27mXjnMPF44+TrFBAJiIi4ibpzrI81N3HjcOwbYy21iwOShSQiYiIuMkgS5ZW2ThAB4xnmwIyERERN7EGmSErLQPA1DqyrFJAJiIi4iaDLVkGAs4nwVCWBiSggExERMRdBlmyxO8HwAgrIMsmBWQiIiJuMshdlrbPCcgIKSDLJgVkIiIiLjLYxrD4fc7dw+EsjUhAAZmIiIi7DHYNmTJkI0IBmYiIiJvES5aDXUMWUYYsmxSQiYiIuMmgM2ROyVIZsuxSQCYiIuImgwzIendZKkOWTQrIRERE3GSwh4trDdmIUEAmIiLiJoNse9G7y1IBWTYpIBMREXGTIe+yVMkymxSQiYiIuIk69Y9KCshERERcxLAHWbL0eLANQ2vIskwBmYiIiJsMdpelYYDfr12WWaaATERExE1i8diAS5bE1pEpQ5ZVCshERETcZLC7LAH8Pq0hyzIFZCIiIm4y2JIlsQyZSpZZpYBMRETETQa7yxKcNWQqWWaVAjIRERE3GULJ0vb5QCXLrFJAJiIi4iZDKFk6GTKVLLNJAZmIiIibDKFk6awhU4YsmxSQiYiIuMigG8OCs8tSa8iySgGZiIiImwylZOn1aZdllikgExERcZOhlCy1yzLrFJCJiIi4yVAaw2qXZdYpIBMREXGToTSG1S7LrFNAJiIi4iZDaQyrXZZZp4BMRETETYbYGFZryLJLAZmIiIibxBJkg20Mq12W2aWATERExE2G2BhWGbLsUkAmIiLiIkNtDKs1ZNmlgExERMRNhrLL0qddltk2rIDs2WefZcmSJVx44YV87WtfA2DTpk0sXryYefPmsXr16sR9t23bxpIlS5g/fz633347kUgEgL1793L11VezYMECli5dSmdn53CGJCIiIocylF2Wfj9EFJBl05ADst27d3PHHXewZs0annjiCV5//XU2btzIsmXLWLNmDRs2bGDr1q1s3LgRgFtuuYUVK1bw9NNPY9s2a9euBeDOO+/kqquuora2lhkzZrBmzZrMzExERET6G84uy3gwJxk35IDs17/+NRdddBETJ07E5/OxevVq8vPzmTJlCpMnT8br9bJ48WJqa2upq6ujp6eHWbNmAbBkyRJqa2sJh8O8+OKLzJ8/P+W6iIiIZMlQzrL0+52PseqWZJ53qA/cuXMnPp+PG264gX379nHuuedywgknUFlZmbhPVVUV9fX17N+/P+V6ZWUl9fX1NDc3U1RUhNfrTbk+GBUVRUOdwqBUVhaPyOuMNm6dN2jubqW5u4/r5l2a73w0zYHPfZxzv8rSABQWZmlgI2u0ve9DDsii0SibN2/m4YcfpqCggKVLl5KXl4eRFHHbto1hGFiWlfZ6/GOyvl8fTmNjB5aV3RRqZWUxDQ3tWX2N0cit8wbNXXN3H7fO3Y3z9jV1UAZgGAOee37Iogg4sLcRu8zK4uhGRi7ed9M0DplEGnJANn78eObMmUN5eTkAF1xwAbW1tXg8nsR9GhoaqKqqYuLEiTQ0NCSuHzhwgKqqKsrLy2lvbycajeLxeBL3FxERkSwZ4i5LALTTMmuGvIbsvPPO4/nnn6etrY1oNMof/vAHFixYwPbt29m5cyfRaJT169dTU1NDdXU1gUCALVu2ALBu3Tpqamrw+XzMnj2bDRs2APD4449TU1OTmZmJiIhIf0PdZQkY6kWWNUPOkM2cOZNPfOITXHXVVYTDYc4++2yuvPJKjj32WG688UaCwSBz585lwYIFAKxatYrly5fT0dHB9OnTufbaawG44447uPXWW7n//vuZNGkS99xzT2ZmJiIiIv0MpTGs7fM5n6hbf9YMOSADuOyyy7jssstSrs2ZM4cnnnii332nTZvGo48+2u96dXU1Dz/88HCGISIiIgM1jF2Whs6zzBp16hcREXGTIZ5lCShDlkUKyERERNzEGkqGzClZag1Z9iggExERcRPtshyVFJCJiIi4iXZZjkoKyERERNxkiGdZAlpDlkUKyERERNxEuyxHJQVkIiIibqJdlqOSAjIRERE3GUJjWK0hyz4FZCIiIi5iDGmXpdaQZZsCMhERETcZ1i5LrSHLFgVkIiIibjKUXZZeJ0Pm+fs2zD27szEq11NAJiIi4iZD2mXpBGQF/30/RV+8OQuDEgVkIiIibjKUNWT5BYnPzXfeyfSIBAVkIiIi7hIvWQ5yDVnji6/Qc+mHMRsPZGdcLqeATERExE2GUrIErClTsSZOcgKy+HNIxiggExERcZMhBmQAVsV4jFAIo7Mjw4MSBWQiIiJuNJiSZYw1fjwAxgGVLTNNAZmIiIiLGENoexFnl5cDYDY1ZnJIggIyERERdxlmyRLQwv4sUEAmIjLWhcMUrP4mdHfneiQyFgylU3+MVV4BgNGoDFmmKSATERnjvH/dQuFdX8X3wvO5HoqMBcMpWY6PZ8gUkGWaAjIRkTHO6HEyY0ZQBz/LAAyjZGkXFWP7/SpZZoECMhGRMc4IBZ1PwgrIZACGUbLEMLDKKzC0qD/jFJCJiIx1PU5AZoQUkMkADKNkCWBXjFeGLAsUkImIjHG9GbJwbgciY8MwSpbgLOzXGrLMU0AmIjLWxTJjypDJwAyjZAlY4ysw99fj/etmHaGUQQrIRETGOKOnx/lEa8hkAIbTGBacXmSeXTsZt+B8/E8+nrmBuZwCMhGRMS5esjRCKlnKAAyzZBm8+FJ6PnIV0anvonD1KmXJMkQBmYjIWBfULksZhOHssgQiZ5xJ+399j84vfBHva69StmgeeQ/9IIMDdCcFZCIiY5wR1C5LGQRreBmyuOClHyZ44SI8298i/4H7MjAwd1NAJiIyxiUCMe2ylIEYZskyweej7X9+Qvf1n8b79lsYba3DH5uLKSATERnrYov6lSGTARlmybKv8CkzAfBufTUjz+dWCshERMY4deqXQRnmLsu+IjNiAdkrL2Xk+dxKAZmIyFiX6EOmkqUMQKZKlvGnq6oiOukovC+/lJHncysFZCIiY5z6kMngZLZkCRA5ZSbeV1/O2PO5kQIyEZExzlCnfhmE4TaGTSdy2ul43vwHnrfezNhzuo0CMhGRsS4Yz5CpZCkDkOGSJUD31R+DvDzy712dsed0GwVkIiJjnPqQyaBkeJclgF1ZSfc1HyfvFz/DrNuTsed1EwVkIiJjXaIPmQIyGYAslCwBgksux4hE8L76Skaf1y28uR6AiIgMjee1rRhWFCMY70OmkqUMQBZKlgBW1QQAzAMNGX1et1BAJiIyRhWtWIYR7MEIZi9D5v3TC3h2vE3wiqsz/tySI9kKyMZXAmA27M/o82ab7/nfY+7ZTbjmXKyjqnM2DpUsRUTGKKOlGaO1BULZW0OW//BDFN711Yw/r+RQlkqW5OVhlZRijKGAzGhspPTSxZTctJT8+/8rp2NRhkxEZIwy29uc9WPe2D/l2dhlGQz2ngQgRwgb2zDIcDgGgFVZidkwdkqW3q2vYNg2bQ/8kOAHP5TbseT01UVEZMiMjg4IhbDz852vsxCQGaEgBLVZ4Ihi2xndYZnMqqwaUyXL+PmbobnngceT07GoZCkiMkYZHe0Y7W2JRf3ZWENm9PQoQ3aEMSw78+XKGHusBGSWBaEQ3q2vED2qGru8ItcjykxA9o1vfINbb70VgE2bNrF48WLmzZvH6tW9DeK2bdvGkiVLmD9/PrfffjuRSASAvXv3cvXVV7NgwQKWLl1KZ2dnJoYkInJkC4edYMm2MVpbgSztsgyFnLVp8XVHMvbZ2QvInJLlGAjIbruN8jNm4dvyIpEZJ+d6NEAGArIXXniBX/3qVwD09PSwbNky1qxZw4YNG9i6dSsbN24E4JZbbmHFihU8/fTT2LbN2rVrAbjzzju56qqrqK2tZcaMGaxZs2a4Q8qowE8fgTFUDxcRdzA62ns/j++ay0aGLNZ0FjWdPXJku2TZ0jKqf17Md/bBd76Dp24Pnh3biUyfkeshAcMMyFpaWli9ejU33HADAK+88gpTpkxh8uTJeL1eFi9eTG1tLXV1dfT09DBr1iwAlixZQm1tLeFwmBdffJH58+enXB81olGK/+Nz8O1v53okIiIpjPb2/tcyGJD51z8BXV2J/1hVtjyCWFb2MmTx1hejuBdZ/n3fgUiE8KxTAYjMOCXHI3IMKyBbsWIFN998MyUlJQDs37+fysrKxO1VVVXU19f3u15ZWUl9fT3Nzc0UFRXhje0Qil8fNTweIie+B158MdcjERFJkS4gI0MlS3PXTkqv+yiBDU/2BmJa2H/kyGrJsgoY3b3IAk+ug0suoX31fYRPO53wmWfnekjAMHZZ/uIXv2DSpEnMmTOHxx57DADLsjCS3mTbtjEM46DX4x+T9f36cCoqioY6hQGx55wJv1hLZUVh1lK8o1llZXGuh5Azmrs7jZm5+/qs6QoEMMOhYY0/8djY78UlRiRRBh1f7IOx8r0ZpDHznmdKvi/x/1nG5/7uqQCMC3eOzp+XpibYWwdnnEH5uXNg818Yn+sxxQw5INuwYQMNDQ1cfPHFtLa20tXVRV1dHZ6kbaMNDQ1UVVUxceJEGpLWYR04cICqqirKy8tpb28nGo3i8XgS9x+MxsYOLMse6jQOybLgW7+czd0t/03TX14ietwJWXmd0aqyspiGhjS/hbuA5q65j3b+3e9QmvS1VVSE0dLCgSGOP3nu3n2NjAM6GprJ7+7BAzTubcTKKxvusEedsfSeZ0phRw95GJiQ8bmb3kIqgLZ/7iQ4Sr6vZt0ePG/+g/C55+N7/gXKAE45ZcTfd9M0DplEGnLK56GHHmL9+vWsW7eOm266ifPPP58f/OAHbN++nZ07dxKNRlm/fj01NTVUV1cTCATYsmULAOvWraOmpgafz8fs2bPZsGEDAI8//jg1NTVDHVLGGQZs8bwPAO9ft+R4NCIivfqWLO3CYoxoFKLR4T95T6zzf1LLi2ycAiC5MgIly/2jpGRpWZR8/GrKPnwJBSu/hvc1p+8YM2fmdlxpZLQGFwgEWLlyJTfeeCMXXXQRxx57LAsWLABg1apV3HXXXSxYsICuri6uvfZaAO644w7Wrl3LRRddxObNm/n85z+fySENi2HA+Lkn0kmhAjIRGVWMjo6Ur+3iWHkoA81hE+vGenoSa8cSvc5k7MviLksKC7EDAczmpuw8/yAF1v4U38t/I/ze0yi8527yf/CAs/Fg4sRcD62fjHTqX7JkCUuWLAFgzpw5PPHEE/3uM23aNB599NF+16urq3n44YczMYysOPv9Nv949ASOeX1nrociIpLQL0NW5JRCjHAIOy9veM8dC75SmsJqUf+RI4u7LAHs4hKMtrasPf9gFNz3HcKzTqVlXS3lc96LZ+cOQnPPw5/rgaXhvlXqg3TWWVGCBGg9EMn1UERE8Lz1JpVVJfj+tAkAO7ZL3YoFZBnZaRkvWXZ3JUqVantx5DBsm6wcZBljlZRgtLdm7wUGqrMTzz/+TmjehRAI0PXZzwMQOWl09B3rSwHZYUyZYmMGfHQ2KyATkdzzbXwOgMBT67EKi7BjbYfiJctD9iKzbfJ+/L/Q3X3I10hkyJKzHArIjhzZLFkCdkkJ5ijIkHm3vYZh24k+Yz1XXUPPkssIXrIkxyNLTwHZABh+f0YbLoqIDJV1VHXic7uoCLuoOPZ5bA3ZIRbfe7a+SvHNn8X/m2cO+RqJrFh773+qhkqWR46slyxLR7xk6fvTJoyW5pRr8YPDE0cj5eXR/r0fEjn1tBEd20ApIBuAqOnDtLJwRpyIyGAl93QsLu4NyAp715AdjNnU6HxsS19O8m7+C/4nH3cW8wNma+/9VLLMPf9vn6F89imJ92fIbLIbkJWUpATz2Wbu2U3ZBxcwbu4c/E+uS5y76t36KlZZGVb10SM2luFQQDYAlseH19JvhyIyCiTtorSLixOlysQuy0OsITNaW5yPyedgdrRTtvAD8Prr5D+whqI7v5w4vzIlyxFUQJZrntdew7Nrx/CzT7YNRvb++7dKRnZRv2fnDsAptZf+2zWUv28mhV+/M3Zw+ClZDT4zSQHZAEQ9fjyW1pCJSO4Z0d5/i+yiEqzi1JLlITNkLS3OfZJaZpi7d+N78c+webOziL+rq3cNWSyAg6RDxiVnjO4u5+Nwl9DYFna2M2QjGJCZe3YD0PLkM7R9/0dETng3+f+1Gu9rr46ag8MHQgHZAFgeHx6VLEVkNEjOkBUVJdpdxD/mf+8+8r/zrZSHFN32H5Rc8xGMWAkyOSBL/Ofe1YXR3eMs+I9nyJJKllrUn3tGlxOQDbvXXBbPsgSn7YXZ2ZGZJsX9nrz/yTyeuj0ARCcfQ/DiJbT99Je0/uwxIie8m9CChZkfQ5YoIBuAqNevkqWIjA6RpAxZcTF2ceouy8Av15L3+GMpD/G++grera9iJkqWSU1l4/+5d3U5GbLuLoz4GrLOpMCts5Pi6z+O5x9/z/SMZIDiAZmRiYAsy7ssgcyuI+vpoXDZLYyvrqDipGPJ+58fJm4y6/Y4zV6T+u+Fzz2f5j9uJnz2+zM3hixTQDYAtseH11aGTERyz+i7hiyxyzK2qN+2IVba8m16HiwLo/EA5oEGjETJsr3/83V3Q08PhmX1azoL4Hnrn+Q9/hi+53+fjWnJAMRLlsPOkGV7l2WJc8pqJsuWRV/6AgU/eIDgksuJnPgeim/5PIW3fxEiETx7dhM9emws3D+UjHTqP9JZXh8+K4SV64GIiCRlyKzSUgjkYZtmIlMGTod9z7bXKbvkIlp/8gvMxgMYwSCePbuc2zs7MJqbnHVhyRmyHqc/Wd/2AQBm4wHntu5ujMZGzKZGoie8O1uzlDR6M2TDq9gYWS5ZWrGfxWEFZEljNJoayfvlWro//m903L0aolEKv7KcggfuwzzQgFm3h+gJJ2Zi6DmlgGwAbK8frx1GRUsRyTUj4gRQbffeT3juedheH5EZJ2PF2l6Ak0mJt7jwvP1WYjG/561/Ord3dFD05dvwvPUmnbfc5jyoqwsj1jDWbE4XkDUmnrvgWysJPFNL0+ZXszJHSc/o6nQ+Ge5B79leQxYrWZrtbQxmFZnn9dcwGw9QsGolvj+/gHX0MTQ/8zvy1v4UIxSi++OfiN3RQ+dX7wLDIP+B+8DnI3Tev2R+IiNMJcsBsL0+vKhkKSKjQNjJkIUWLsaadBR2ZSWhDywAf+/pfEZ3d+I/b8/rryWum7tjGbKOdsw9uzGamjBiz0d398AyZF1dTsYtFqDJCIpnyCLD3PU/UmvIBpEh8/75T5SfO4eySxfjfeN1uv/tejy7dlBw373k//D7hE87nehJ01MeE7z8Ixi2jREKjZleY4eiDNkAWD4/Plv5MREZBWL/GdteX8pl29f7tdHTk1i47319a+/1WMNMo73duU843GdRfyxDliYgM5IyZEZsA0C2My2SKv7+DDtDZllk8zDL3oBs4OdZ5j/4PazSMtrve4Dwe0/HHj8ez66dFPzXamzDoP3u1f0eE5lxCtGjqvHsrSN6BARkypANhNeHn3Da7bYiIiMpXrLE2+f36aQMGYDR1OTc7Y1t/Z+jo8MpQYZCKW0v4mdcxhf/JzPjO+a6YgGZZQ0/MJBBiWc9Ez8DQ5Xtw8WLB7eo36x/h8D6J+i58qOE5l2IPX48AF03fQHbNOn6/L8TPvf8/g80DCc7DEdEhkwB2QAkfvMcbppYRGS4wukDMtuXGpAlSoxpjtkx29udRf3hUO/ztbQ4i71JCr7iz52fn/jc6O7CiLXDSKxpkuwIhSj8yvLeExbifcgOcRrDgNg29giULPv+HB1M4NG1GJEI3R//t5TrkdPPoOnlN+i69csHfWzPtR8ndE4NkRPfM/QBjxIKyAYi/g/dcLcai4gMkxGJYHu9/UuF/tQSZjwgi4t3ZrcLCjC6Op11SKFwb9uLA6n3T3ls/OBy4uvTuhKfS/Z4t75CwZp78f1+I5DU9mLYGbLstr0gLw/b7x9whsz3x98TOeHdWMce1+82a8LEQ441cvJMWh9bD4WFQx7uaKGAbCBiGbJhp4lFRIYrEulfrqR/hixesgQnGLMmTwFIWWuTkiE7xCL9+PFM4GRpEgFZPGMjWRHPbiZKlfHv+yjfZQlOj7y+AZm5/W2nj13y+CMRfH96gfBZY6eBa7YoIBuI2NoMO6iATERyLBLut6Af6LeGLN72AsAuL8eaMAFIXWtjJK8hO0RAltLjrCupZNmtgCyr4rteu7ogGu0tPw+7Uz9Z3WUJzs+M0ZF6OH3Z5ZdQtmQR5aefgrm3DgDvqy9jdrQTPuvsrI5nLFBANhCxDFmkWwGZiOSWEQ6DL80G+di/U1asS7qZVIK0KsY7R8sA0aMnpz4uXnbsU360Cwqcj4aBnVQOSi5Z0qmALJuM7niGrCsl+B3u0UlGljv1g/Nz6HnzTQruuZuS666h+POfwbNrB523fRmztZXipZ/At+l5Ao/9AoDwWedkdTxjgdpeDIARW5sR7Q7pGyYiuRWOQLoMmWFg+/1Ep74L85WXMBrTB2TWUdWpDzvIwnyrtAxPVxcEAs6f+P07OhJrx5Qhy65EX7iuTuhKCpjHQMnSmjSJwNNP4Xv1ZazKKsyG/QT/5QN03XwL0aOqKbnxBvyXXARA5MRpzloxl1N8MRCxUkC0RxkyEcmxaGxRfxodd63Czs/H9+lPYjY1YpWXYzY1YVeMx6p0Wgn0zZAZnekDMru0FPbtxfYHsJMDsqRAT2vIsqt3DVlXSuCckbYXWS5Ztn9nDV27dhKdMhW7tAzfH/9AZPoMAIIfuYqmmadiNuyHcIjo8TqCCxSQDUg8QxbpHswhECIimeeULNNkyICeaz6O5603nftFIkSOPgajrQ2rYjzRaSdhlZZhTX1X6vMdJKiKHxCN34/t7w3IzNj6MVCGLOuSMmQp79Nw215kuTEsgF1eQaS8IvF1+P1zU26PTnsP0Wljv1VFJikgGwAj4GTIrB41QRSRHIuED5ohA7DzC3o/Lyqi/Vv3Epl5KtH3nERwwUI8dbtT7m8kBVjJrLIy5zny8vptGEg8Vm0vsurga8hGf8lSBk8B2QCYgdgaMpUsRSTHjHDkoBkySG3iaufnE7zyo7035uWl9BSDw2fIbL8/pWSZ+lg1hs2meBCW3GoEyEBPzOw2hpWh0TsyAMmL+kVEcioSAc/AMmQU9G+WaRUWpXxt9NkpacVaXMQzZAQCva1/8vJSH6sMWVYl1pB1dqQEZMPdZckI7LKUwVNANgBmXqxkGdTRSSKSY5FwykHi/QQCKV35+yksdFpZxDIkRldqydIuL3c+JjJkAeyAE4hZVRNSn0uL+ofM3P724e8UW0NGn0X96TJk8eOVvJv/QuDxXx76eVWyHJUUkA1AvGSpgExEcs0Ih9N26u+9gwGxLFnagMwwsItLEsFV35KlFQ/ISsucC35/ou2FVVmZ+lRa1D8k3ldfpuKMWXj/tqX3omUR+PlPnGCruxs6O1N3WSZnI/usITPq66k46Th8z/6Ggu9+h8Lltx56ALYNpgKy0UZryAagN0OmkqWI5NhBjk5KZufnYXR1ppYvk3Ss+jbmO/soWrEspe2FbRiJQCx5Ub8dK1lalakZMrW9GBpz507n4549cOppAHj/upmSG2+gtaKCwOOPYR5owIrtUnT6kDnvk22azjrCJJ7972CEw3hffw1zX53TTiLNz4nR3kb5aTMw2tqIzJyV5VnKYClDNgCevFiGTIv6RSTHjEjk0CVLeteRpc2QAcFLLiVyyizn+ZJLYfn52LF1Z3ZhIbZppizqTy5Z2nl5CsiGyGx2zhk129v6XTMaG/G8/Rbmrp19+pA532u7tLRfhix+YoK5rw5z3z4M28Y80JC4ObDuMQrv/DJmfT1mS8uIdOqXwVNANgDxkqU93N4vIiLDFTlMyZLenZZ2mkX9ifvEgrrkoMrOy+vdpRnIg7x88Pcu6k8uWVrjKxWQDZERD75aW3uvxQ7iNltbMFpbMNrb+/Uhs2Pl5r6Hi8dLx57duzD31zvPU7eHwv+3AvOdffif+j/yfvYIRlIAiKH//kcblSwHwJOvw8VFZJQIDyJDltQCo59YkGV0dTllMMvCzi/ozZAFAtj5ediB3sawyRkyq2K81pANkdncDIDR1j8gM5qbMZubnaxY3wxZfoHz3vfp1B8PjL0vv+RkvwD/b39NwXe/TfRdxzoBXVtb4jWcBylDNtooIBuARMlSAZmI5JhxmLYXAMQzZIWHypD1Nnu1i0swWlucDFlBLIiL9Syzi4p7F/XHAjI7EMAuLlbbiyFKZMja2/D/uhZC4URwZsQzZOFwommvEQphtLc5JWi/H6NPtSaRIdu3N3HN98Ifnds6OzA6OzHC4ZQypgKy0UcB2QDEM2TDPq5CRGS4Igc/Oimut2SZfg0ZkNJ93y4pgdYWJ0MWz675/bQ98EPnUHLTpPuafyVy0vTE89oFBRj79g1zMkcWc9dOSj75MVof+QUE/GCa/RrxAphNsTVkbW0UfPtb0NND+NzzAfDU1SX6jJkHes8NNRsPYBcUYnsPniFL5tvyonNbZ2cisDPr6pIGoZLlaKN3ZAC8+VpDJiKjRDiM7TvcGrJYIHaIgCy57GnHmsGSl9ebXQvkEXnvbKxjpmAdPZmOb32ntzdZQSF2foFKln14X/orvr/9Fe+21yj+1HUUff6zmG+/RfmMEzB37kjcz0xaQ2Y0NWI2NyXKiZ4d23vv17A/5XO7IB/8vv5ryPqcmGD7/b3lzo6OxE5az949vfdRhmzUUUA2APGSpTJkIpJrRiQC3gFmyA7S9gJIyZBZJSWJxyWyann9j0uK32YXFjoZMi3qT5FYG9bagmfnDjy7d+J9Yxue/fV4/74tcb/kkqXZeACzqRGj3SlZepICN6OnJxE4e976J1bVRKfUHElte5FcOrZ9PqLHv7v3tqQu/+bepAyZArJRRyXLAfAWxBb1KyATkVyLRA55uDgkBU6HzJAlryFzymp2fn4iW5Z2h2ZenrPTr6AA8vOVIYvxr38Cu7Aw0S3fbG3FbGnBsqzetWGxMiUklSwbGzFbYo/Z72TD+ma7rPIKPPXvYLa0EJ08Gc+unRjBoPOYt9/CbGtNCYytiZOITpqE9/WtzvN1dKhkOUYoIBuAeMly+Ae6iogMj9Opf6BryA6+qB9/0nP4A06wlZdPzwc/hFVahjXpqDQv7pwCkChZKkMGQME9d2OPG0dk5qkAGC0tGC3NmNiY8SAtlj3DtjFanM+Ts2HJnyezyyug/h0ArKMnOwv3O9oBKLzrq3i3vUZo7nnYHg9GNIo1cRLWxEmJxztryPqXLJUhG30UIg9AIiBThkxEci0ShsOsITvk0UkxKRkyv89ZO5aXB0VFhBYuPvjjCvJ7F/UHgxCNDm78RyCjpxvzwIFEoGXu3YMRiThrxGIZMKMlVqbsaHfKzqRmw8y6PaRjVVQkPo8ePdkpYcY69Zv7651yZ3c31vhK7IICopOOwpowsXdsrS29GbXGxqRBKyAbbZQhGwCf3yCMVxkyEcm98ABKlnnOYeADXUOG1wcXXUT4tDMP+/J2QSF2YVHiuY3urrQ7Cd3ECAahrS1Rfoxnu4xwGDOW3TKbYuvLYuXKaNUEPLEmrkCif1hf8eOTAKzJx4DPjxHr1G82NTpBX1cndkEBXR+7jsjJMxPNYaPHTE183n/QyseMNgrIBsDngzD9txqLiIw0I3r4Rf3Rqe/Cqqhw2lkcjMfT2xDW74dH/oeehvbDvn7HHV/FmnQU3ldedi50dYPbA7LuboyW5sRi/dRSpHNuZfy2+A5La+q7UgIyIO1GCTt22DvEM2S9yQGzsdEJ+hoboaCQrv+IHSre2YlVMZ68R3+Ob+PvDjLooc1Vskch8gD4fBDC32+rsYjIiAuHD9upP3jph2l86Y3ULFg68dsPE+AlCy2+hMjs9yXKoVrYDwSDGJEInl1O8BX/6Hy+A3DWkOXfdy+FK5YBEJ0ytd/TRCcfA4CVFITFM2S2aTrr+nx+Zx2hbfcGefXvpJanCwsJXbQIu7Aw5bzMFJY9pKlK9iggG4B4hszos9VYRGRE2TZGNHrYsywxjER3/UM+XWwd2eH6mqV9bOwUAKOjY9CPPdIYsTMnzT27Y1/3JG6Lrw0zmpvI+9kj+P+0CXCymJDaD6w3IKvAKixybo+tIbMmTgKfz8lmhp3O/kZs/Z65b1/a8rRdVHTYMcvooYBsABIZsrAyZCKSQ/F1rIcLyAYqvtPSd5hMWhrxdWOuD8ii0URnfcPun3WK/yJvNjfh2b2r92HHTAHAHjcOK9Zw14pfKy1LtCKxxjnZMuvoyc4DvV6McAgjaYG+2dqSdgOHXdg/IEt3qLyMDgrIBsDjiWXIolpDJiI5FPvP3R5EifFQEjstD1MCTfvYWPbF6Dz8urMjWlI27FDMvXWp/cJiJUurYnxinVj0mNi1ceMS31+7qBjb7ycaC8hsvx9C4cRatLj0AVlv2xM7Vp6Ot8SI9yaT0UMB2QAYRrxkqYBMRHIn8W/QEAKotGLPc7g1aenEG8ia7e4OyIw+AZmVJisFvdmz1h/8D02btiQyX3Z5RWLNWLxkmZwhs/PyCC5cTGjeAueJvM7/RWZTY8rzpw3IkkqW8UAs0RJDB8OPOgrIBihs+DEVkIlILsX6Tw1lzVc6iUBsOBkytwdkwT4BWTzzFStDAkST+oJFjzuB6PEnYJfGypQV4xML963qamzTxC4rwy6KnZiQl0/7Aw8RXHK587XfD6HUkiUcLEOWFJDFxhBv+KuS5egzrIDsu9/9LgsXLmThwoXcfffdAGzatInFixczb948Vq9enbjvtm3bWLJkCfPnz+f2228nEku97927l6uvvpoFCxawdOlSOjs7075WrkUMnwIyEcmpRIbMk6k1ZLFF/UMogcYzOEaHywOyPovj47snrcrKxIkJVmwBP4B1TGzhfizD6JQsYzspS0vpXLaCnsuvSHx/yc9LfUGfDyMaTW3ySvpTGaykDFk0FohFJzqBWd8jmiT3hhyQbdq0ieeff55f/epXPP7447z22musX7+eZcuWsWbNGjZs2MDWrVvZuHEjALfccgsrVqzg6aefxrZt1q5dC8Cdd97JVVddRW1tLTNmzGDNmjWZmVmGRQ0fZlSL+kUkh+I7vTNUskysIfMPJUMWC8hcniGjJ5jyZWL3ZFnvYv34NWvcuESpl4ICrMoqosef0Ltwv7iU7pu+QOS9s5NKlvmprxd77836d7C93t4sZ36f+wEkrSGzJsVLlrE1ZDphYdQZckBWWVnJrbfeit/vx+fzcdxxx7Fjxw6mTJnC5MmT8Xq9LF68mNraWurq6ujp6WHWrFkALFmyhNraWsLhMC+++CLz589PuT4ahU0/phb1i0guxXbzHa5T/4D5h76GDI/HaWTq8oDsoBmyceMSZcl4QBadPCXpgQZNf3yR7k98iuiUKViFRYn7A1hJa8iSxYNoc/872OPKE485VMnS9vsTWThr4sR+95PRYcgB2QknnJAIsHbs2MFTTz2FYRhUVlYm7lNVVUV9fT379+9PuV5ZWUl9fT3Nzc0UFRXhjf3jEr8+GjkZMvUhE5HcSfRCzFBA1rvLcvBtLwCsomLX79aLnxMZD4gSGbLSMuy+GbLYov04u2wc+Hz0XHsdzX/4c0rvuINnyJz33qyvx6qoSGTh0pYs4wFZYSFW7NSG5IPHZXQZ9t/qN998k0996lN88YtfxOPxsGPHjsRttm1jGAaWZWEkNb+LX49/TNb368OpqDh447tMinr8+Kx2KivddUSI2+abTHN3p1E99/3Of9glFSWQiXEWOv/ZF5c7zzXouZeVkh/qJn80f88GYFjvecD5P8s45hh44w3KTp0OQN5RE6DLyR6WvPdk564nHn/w16quSP168lFgmoyfOhGSG7yWO4GV/8B+mDABurrgbSieUE5x3+c+ZgIAZlERxSe/B3w+yt43K+Uuo/rnPctG29yHFZBt2bKFm266iWXLlrFw4UL+8pe/0NDQkLi9oaGBqqoqJk6cmHL9wIEDVFVVUV5eTnt7O9FoFI/Hk7j/YDQ2dmBl+QiIyspiIoYXIiEaBnDW25GisrLYVfNNprlr7qORp76FcqC1K0IoA+MswSQAtPVEKYFBz70svxDrQBNto/h7djjDfc/99c2UAj2nnIo3GKLFyGM80OkvwJNfSB7QGCgh8NW7CJ3/AaIDfC3jg5fjnfpuwt02dPc+Jq8nSjFg7d1H+PgTMfDgB1ojZr+fCSNoMB6I5BfQfPr7Mf/6GlZeGZVJ9xnNP+/ZlIu/66ZpHDKJNOSS5b59+/jMZz7DqlWrWLhwIQAzZ85k+/bt7Ny5k2g0yvr166mpqaG6uppAIMCWLVsAWLduHTU1Nfh8PmbPns2GDRsAePzxx6mpqRnqkLIqavrwalG/iORQbx+yDK0hG0ZjWHDKaqbLO/XH15B13XgzzX/cjF1aRufn/4Pg4ksSJUurpJTuT32G6AnvHvDz2iWlhM/p//9hfL2f2d6GVV5xmDVkhb0fDaO3B5mMSkP+W/3ggw8SDAZZuXJl4toVV1zBypUrufHGGwkGg8ydO5cFC5xmdqtWrWL58uV0dHQwffp0rr32WgDuuOMObr31Vu6//34mTZrEPffcM8wpZUfE48cT1hoyEcmheB+yTK0hG0bbC3B2WppJB2m7UnwNWX5+Ym1f17IVAESPnoxVVpay23HYkg6Mjx5zDNhW7PX7B2QUFGAbRtojlGT0GfLf6uXLl7N8+fK0tz3xxBP9rk2bNo1HH3203/Xq6moefvjhoQ5jxFgeH56gdlmKHFEsC6Ozo7cVwShnxDcWZejopERmbAhtL8BpDuv6PmSxjvd2IK/fbd2fXErw0g87x71kSHLwHD32eMwm5wildBkyYsGY3ScgbF/5LaxjjqG0/yMkh9Spf4Cipg+vpZKlyJEksPanlM86CaOlmfx7V8Mf/5hyu/elv2LWv5Oj0aURzuzRScPOkBUXKyCLH53Ut4ErQH4+VvXRmX3B5AzZscf1tsooTBOQ4ZQr+wZrPdd9ktAF8zM7Lhk2BWQDZHl8eGxlyESOJN7XXsVsbyPwy19Q9LU74Ic/xPPaVoo+92mIRCi98lIKVn8z18PsFclwH7JEY9ihtb2wi0ucPmR2djdWjWbxo5PSZciyIfnYrOi7ju1tKluYfsdg179/iZ6rPzYiY5PhydDf6iOf5XEyZArJRMaoaBSjvQ27bByBR39O5NT34qmrA6DwW7G1sHv3EtjwJPk/fYTuT9yA2diImbRDPNeMcIb7kMUbww55DVkRRjjsrKPKG5mAZNTp6cY2jCEHtYOW3DOuoIDgpZdjl5djT5iQfngf/7eRGZcMmzJkAxT25VMWbaLsghry/3sNRltrrockIoOQ9z8/pPy0kzH31lH8mevJv/8+zL17ADAPHHDuVFeHuW8vAL7NfwHAaGnOyXjTisQX9WdqDVl8l+XQAjwrcZ6le3daGj2xYDSD68QOqU+52i4pJXjxkpF5bckqZcgG6Kmpn6K93eAa3+8pWn4rhf/5VcKz34ddUIBdkI9dUEj49DOIvO8MZxFlQQG26Ult6CciOeP762bM9jbyH1iDYdt43v4nZl0dttfb2wG/rg7PeKcXou/FPwNgNI+egKy37UWGArL4GrIhdurvPc+yDXv8+MyMaYwxerr7HW+UTfG2F9GjqkfsNWVkKEM2QI2lx3JX+d20PPUszb/eSM8lSzA6O/Ds2on3b38l8NR6Sj73acrnnEbFKScy/vjJVB57FGUfmEvgp49g1u3B3LkDo6nR1estRLLGtin60hfw/uXPaW/2vPl3APL+9yEAvG9sw9xfT3DRB7F9PkLvnwtNTXjefgvozZCZrS34f/M0FdOm5j4zHl/Un7Gjk2KB3VD7kBUpQ0Yw2P94oywyurqA/scwydinDNkAeb0QDjsp6cjMU+n49n2pd7BtvC//Dc8/38To7MTo6sLo6iTwy7WUfO7TKXeNTn0XoXPPJzr1WOxAgND5F2C969iRmorIEcloayX/oR9g5+UTed8ZqTfaNp433wTAjJ29aB5w1oaF555P++r7CDz5OP4/bMSzcwcAnh3bnedtbsb7ysuYTU143nij/3OPpEhm+5Al1j0Nte1FrGRpdrQTzcyIxhyjuzvlDMpsi8b+r+haeuOIvaaMDAVkA+TzJf4tTM8wiMx6L5FZ70253PWFL+L92xa8r7yMHQhgNjfj3/gsgccexUz6bbvzC7fQdeuXszR6kSOf+Y7TnsLcX59y3f/rWqzxlZgd7VhlZZgtLc7XsYAselQ1FBYetIu52dGOuddZV+Z5+585DcgSpdVMtb3wDb/tBTglS3P3Ljy7dhI+7XTKLrmQzttWEJ57XkbGOZoZwaDTFHaEWEdPpmF/24i9nowcBWQD5PPZiWrBoBgGkffOJvLe2YlL3Z++EWwbo70No7mZwm98ncJ7voldUEjowkWDOl5DRBzmO/ucj/v3914MBim59kqsKmcHWs/lV1Dw/e/Rc+mHKXjAyXLH+0RZk45KPMz2eDCivTkfzz//AYD3rX8SzOosDiMcb3uRqTVkmStZFn7zLgJP/IqWxzfg++sW/M/+xhUBGT3d2COYIZMjl9aQDZDXe5gM2WAZBnZJKdaUqbR/+z5CZ7+foq99hXFzz8SI7/gSkQHrDch6G7madXswolE8sZ2T3UtvpOOrd9H1+f9I3Ce+ONqaNClxLXLyKSnP7f2Hs/4svr4sVxKL+jNUsgzPei/hM+ZglVcM6fF2iXPCgdHcjGfb6xhdXfifqQWcbKIbGCO8hkyOXArIBsjng7Y2g89/PsCrr2b42+b30/roE7Q++DBGJILvT5sy+/wiLhDvqJ9csvTs2Z343Copxao+mu5PfQa7ooLoUdVYpWWJndB2SSnESk/h052yZPSYKc5zxsqbnrcGHmSY29/GyHQPs3gfsgwdLh45/Qxannx6yGugrMoqrJJSvK9vxRvbNBFY9xgAnn++mZExjnYjvYZMjlwKyAboggsinHyyxZNP+rjgggK+/OUAsc0umeHxEJp/IXZeHr4//fHw9xeRFIkMWXNz4sBns87pMxY9ZiqRU2am9IqKnvDuRMAFOLdVV2ObZmKJQeQ9J6W8hmf7W2BZAxpP2eWXUPKJazEOHCD/v9ckxjQsme5DNlymSWTmqQSeWp/Y/ed90ynvenbuwP+bpym8/YsD/p6NSSO8hkyOXFpDNkDnnRflvPO6aG2Fu+4K8MADfh54wI/PZ1NUBEVFNkVFNuPG2ZSX2/j9TlbN57PJz4fJky2uvDJM6aFOc/X7Cc9+H74/vTBi8xLJKcsCM/Z7YU8Pnrffcnr4lZZil5Y5t/X0UHzzZ+m58qOEa8496FN53kkqVR5owKo+Gs/uXdiGQXPts+D1pNy/4xvfgp4+QVJ1NVZHJ9Gp7wIgctJ0Ak8/BUD06Ml49uzG3Lf3sOcTmnvr8OzagWfXDkqvuhTfS38Dw6D7k0sH9n05iIz3IcuAyKnvxf+H5wCwTRPDspw1eJEIRV/6dzy7dxE99nh6/u361Ad2dEBRkdOmxOtJWWdLOAzRKPj9mDu2Y019F0ZnB9i2k8k8FMty/ni9GC3N2GXjMjrfvoye7hE7NkmObArIBqm0FFauDLJoUYQXX/TQ0QEdHUbsDzQ3G/z97ybhsEEkAqEQ9PQYtLUZfPObAb7xjR4uu+zgi9HCZ55FwT13Y+zfj11VNYIzE8kO3/O/p+TjVxO8+ENEpp+MXVSEXVSM582/U/Cde5yDjwsKMPfWYYRCicfZBYWEzr+A8KxTyfvlWvwbn6Vp45+xKyvTvo75zj5sw8Cwbcz99U5Atmc31oSJaZuWRo89vv+TfOQj9PzjbSKz3kvnshX0XHIphatXARA+Yw6ePbvxvPXPtAGZ7/nf4932Gt2fXIo31sPMNk18L/0Nu6CQgtWr6L7qWjx1e/C88TqhxZcQeOJXhM6uccYX60+Y9+ADhC6YjzVlqhOUeDwUrFpJ8MJFGO3tzjE9Hk+/18+V8Kmn9X5+dg3+PzxH+Kz34//Dc05A7PdT9NU7MFtbYuVMg+ixxxH4vycI/ssH8P/ut+DxEFxyOb4//oHQuefj//XTGB0dWEcdhffNfxB5z0mYu3Zh2Bahc/8F7ysvETrvX/Bteh6jp4fwWecQWL+O4PwL8b6xDaOtjfBZ55D36M9pfeTnhOZdmLX5Gz097j02SjJKAdkQnXNOlHPOGXjnnVdfNVm2LMCnP53PT38a4bLLwnzgA1EKC22Ss93hOWdjWBbjZxxP8MJFtN333+r2L2Oaf+PvMDrayVv7U4zgj1JuC35gPnZ5BYRDWIsuJjLjZAiFMNta8bz5Jnn/+0MC69cROWkGnrfepPSjl9N1079j7quj55p/TVm7Y9a/Q/T4E/C++Y/ETktzz26soycPfLBLl9LV0A7gLPxP2mkZPvv95P1yLd6/b0ubqSv4r9X4f/dbQjXn4XvxL9h5eXQt/Sz+3/yazq98jbJLF5P/4H8TeOYpvC/+mc6vraTo9i/Rs+RyJ0B54ld0ful2ipd9kZ5XXiZy3PHk//D7tP33jyj85l14/7YFz84dhOec3ZtVHAUipzqtfqJHVRN+3xn4//AcwYsWJbJmbWu+T8EDayhc+TWiU6Zie734f/M0wcWX4H9qPeFzz8dobyfv5z8hfMYc8n7yMNFpJxGuORfP22/RecttBNY/Qfj8C8Cy8P15E5GTZ5L300eITn0XVsV4Ar9cS+iCeQT+70msSUdhl5aR9+jPsX0+/BvWZz0gU4ZMMkEB2Qg5+WSLxx7r5v77/Tz8sI/PfS4/6bYoZ54ZZcaMKKefVsOMu1fj2bGd/O99l/HvPga8XuzCQtrvvZ/QBxbkcBYig+d5fSvRE99D8zPPYbS2YnS0Y3Z2YHu8RE+afsjHRo87jsL//H+0f3M15v79FN/8GUr/9WrAOX+y69blzh1tG/OdfQQXX+IEZLEF/p7duwi/97SDPf0ABu/BKi3DbG0hMuNkrPGVeF99pf/9bBvvS38FoOC738bzz38QnvVeum5bQddtKwAIXjCPwm+tdBaBA0W3fwmAwK8eBcPAsCxKbnAOgvb/35P48vPx7K+n+HNOmTPwm2cAaL8+tdF0rlmTjiI6YSLRae8hctpsbMMgPPc8rPJyMAxCCz9IaPEleN7+J9Gjjnaa0YbDkJeH0dzklKbDYcx39mFNmeocw1RQmJIF7Lrltv4v3NHhZKZME7q7obDQqSyUlIDHg7m3jqI7v4x/4++c7GO2zprs6cHOV0Amw6eAbAT5fHDTTSFuvDHEli0mf/mLh44Ogz/+0cOPf+yjq8uPz5fHSy99gspKm9C8Bfh/+2uwLPy/fYbiz1xP87N/HNxv/CI55n39NcJnngWBAHZVFXZVFQNd4t19w2fp/vgnEiWhptPPwPvG6+T95H8p+K/VBD90GdETp2E0NWGEw0ROngmP/cLZaWlZmHvrsD74oWGN3y4tg9YWrMoqIiefgvfVV5zyanMz0ekzADB3bMdsbiY6cRKBX/zMGfunb0p5nq5blxO4oAartIyeDzv90DqWf4WC79wDgQDBmnPJe+wXBOctIPBMLbS3Yefn4337LSLTT8bz+lantLf44mHNJ+MMg7bv/w92WRnRE6fRtPlVrMnH0HPph7ErxicCq+hxJ/Q+JnbNHlfufB0IOCVawC4uGdjrJlcOCgudxyYt87CmTCU09zwC69dR8M27sEtK6L7hs0Ob4yEYwR5QhkwyQAFZDhgGzJ5tMXt2739LlgXPPefhiisKeO45D5dfHiF81jmEzzoHgO5rPs64C2oouv1LtP3PT3I1dJFBMVqa8dTtofukGUN/kqT1OXZVFeGqKiInzSBQ+xT5/72GzttWkP/IjwCITp6MVV6Oub8es/4djHCY6DB/gbHGjcOzawfW+EoiJ88kf829FN/wb3j/vo3GV/4BgQC+v20BoP17D+J/phbv61vpWXJ5yvNETplF5y23YVUfTc/FS4jMOIXg5VcQPqcGu6AQq7qa8Dk19HzoMipOPxnbH6D73z5F0VdX0PWpT+N/7rfg9Tkl3lEmcuacxOfxMxY7v353roaTEIo1pi1ctRKA8GmnEzm9/7Fa3ldeInLie5xAMRJxfuY6O6GgADo7MVtb0m/kiEYxwuERPVxcjlwKyEYJ04Rzz40yfrzFs896ufzy1IX/1rHH0b30sxR+8y48r21N/GYuMpp5t70OQGT6oUuTg2WPH09wwYUE/u8JzMZGAhuexDZNou+ehlU1gcC6xwg89igA0SlTDvNsh3mtsjKssjIIBIicfApGJII/1iswsH4dvj+/gOftt7Hz8wmffkbil6h0kktvwSs/CpCyu7Dnox8DoG3ND5xd1zNPBa+X4CWXErzi6mHNw42sqe8iOG8B1oRJ+J95ipJPfAwjEiF01jmYTY2YjY1w1ETG/eY3RI47HiMUwmw8QPjMs/D97rdEZs7C3LsXz/56J0u5/W0iJ0131jm+s49orC2KnV+Q45nKkWD0rAyVRFD23HOetG17uj/xKayiYko+9a8UX/9xiv79c5h760Z+oHJE8L70V/J+8jCeN7ZlrU+U5/WtAETfk9mADCB48aWYTU0ENjxJ1w2fpfGN7USnvYfwaadj+wMEL15C+ze/Tfj95w7rdaLHHkf0hBOB1A7+VnEJxTd/lvwfPYj/978jMuOUjLWjCJ97vhPYFRbSvfSz2sU3DG2PrKXjW9+h82srMXq6Cc9+H/5nf4Nn+9vYhYXw4ot0feZz4PViVU0geMF8vH/dTM9V12A2NWNNnkznF76IVVxMz6WXO/3k/H7C57wfc389PVdcTfCSJbmephwBDNuO7bUeoxobO7Cs7E6hsrKYhtjOq2z75S+9LF2az+mnR5k3L8LHPhaK9TNz1sLm/fD75P/PgxAK4dmzm/BZ59D6s8eysmB1JOc92rhh7uPmnpnIYNn5+dj+AFZFBd6yUiJt7c52/mjUWRBt2xiWFWvNYCeuYVlgk/K1YUWdsk80imFZWOPG0fjGjsz/jPb0UHHScRjRCI1bXkvb2mKw0r7vwaAzn8JCsCwqTjiGyCkzib77RPIf+gHdH/0YRKOEa84leOmHhz2GXHHDz3xCJOL8Bmya7pp3H5r7yM7dNA0qKg7eNUEly1Fm3rwICxaEeecdk69/PcDXv+5s6/f7bVav7uHy6z5Jz3WfBCD/gfso+vJtFK5YRvS4451/YAwj5Y/d5+u0f0wz0b/JaNiP2drqXK8cR17EuT3+H65dXk5w0cWjqg+SDJ6xfz/eba/T9alPE5lxCt7XtkIkjNnQgDcSJDJ5KuTlYXs8iZ8RSP65IfHzlvozZjrnLHo82B4TTA+R02ZnZ4dbXh6dK/6fsws5A8HYQQUCve01TJO2hx7Bqq7GNp2/Ax0rvppYVC5jRIbOAhXJJGXIBiBXv0X8+c8eXnzRxLYNnnrKy9atJk891cX06bHyUiRC6Uc+hP8PG0d0XB1fvYvuT31mRF9zpB3pvzkGfvUoJZ+6juanf0fk1NS2EEf63A9Fc3ff3N06b9DclSGTATvjjChnnOE0pvzIR8Kce24Bd9wR4NFHnT5GeL20/vJJ6OrCbGvtLRsd7I9lYSTKTfS7DcAaX4k9bhzYNpVFXhp31Sd6+NgYlHz2egruuZueSz+S3azEWNTVhdHZCT4vti9xdlbmskOJEmGsp9IwspS+P2zEKiklcsqszIxNRESGRQHZGFFVZfOJT4RZuTLAm2+anHBC0iLsggKsgizs8ikpxpqQGkx03PE1xv3LOYw/6ViiEydhVR+NXVBI5ORTiB59NOQXOOuRCgqdA3d9PqckGggQPepo7KIip/zTt2QQX6fU2YHvL3/C2L8fs7kZo6UZIxh0FlafOA2rzAkW8fuIHjMVbBvPm//As2M7RlsrZmuL03y0rRWztRWjvR2saNL6ptg5d5YNttUb5KTcFgVsxgXDEI2AYWJ7vc5ZiGmCWSMawXxnn3OodRq23x8L0GJz7hsMx+Zv2P3HlBh3n0S2bRhYR1VjBwIYkagz5th6r+gJJxI5+RSsivFgOdvyCYcwQmEIBTGCIQJPrXcWjav0LCIyKiggG0M++tEw99zj5ytfCXD++REKC20+9KFI8ukxWRedcTItTzyNf9Mf8Lz9Fua+fRjtreT/4Hsp5xAejm2aTqNQnx8jHEp0L4+vZUvcz+MBn89ZYN73OTwejGj646usklLngOqiImyPN7aAN7YWyjB7187FFvbi9WInrhtQmO+cmuOJBWGRMEYkkn5Nnukh/L45RI8+Gruo2DkAOhzBCAUhHHYColAIIxxKzDHl8cSC3vharfgfw8A2k9Zmmb3jJhTCs3sXRMLgia/Z8mBYFt5XX+n3ftiG4Xy//c56KLuwmJ5Y2wUREck9BWRjSFWVzUc+Eubhh/38+tfOW/fGGyG+8pXgiI4jcsaZRM44M/ViKITR3o7R3YXR3Y3R1ekEWZGIk+Hp6sKs2+PcFgpCsAcjGIJwCHz+3saKHg/hM88ieswU7PJy7KJi51icuj14//EGRkeHE7R1deF5+y3w+4lOfRfRE96NVTYOu6zMecwwMz+VlcW0jeW1FZYFXV1OhjK2yF5EREYvBWRjzKpVQW6/PYhtGyxfHuCHP/Rxww0hJk7M8d4Mvx+7ogKbLHQRNwysyccQinUAlwEwTR1KLyIyhiggG2MMA8rLAWy+9KUg69Z5mTWrkLw8yMuz8fmcJVpO3zIbvx8CAZuyMqiosCkpsZOqYr2f+3xOBi4vz8bjcU4MmT4d2ttTewcXFtpMnTqmN+aKiIiMOgrIxrCpU21+8pNu/vQnD93dBsEghEIQChmEQk4/y3DYuV5XZ/DKKybt7UZiLXk02rt23LIOthOwf3+lT34yxNKlISor7RFdvyYiInKkUkA2xp17bpRzz02/sH0wwmFoaHCCt2gU2tsNuroKaW7uTrnf8897+P73/Xz/+34KCmw++MEIK1f2kI1NniIiIm6hgEwAp2R51FHJpUibykpoaEg95HzRogiLFkXYscPkb38z+fGPfezYkc9ll0UYN86muNhOrCP3++3YR/D57ETD84oKOyuN20VERMYqBWQyaOecE+Wcc6J89KNw9tlRPv/5PP70p4H/KE2fHuXKK8NUVdmMG2dTXm6Tlwcej01JCYwfrzVqIiLiLgrIZFiWLImwcGEHTU0GBw4YdHYaRCJOCdT5YxBrw0UoZNDSAo884mf58ry0z2eaNldfHebUUy3OOivCsccqOBMRkSOfAjIZtkAAJk2ymTRpYMHTpz8dpqHBoLnZ+dPU1Lt27a9/9fCjH/l4+GEDr9dm3rwIEyfafPzjYaZNsw7/5CIiImOQAjIZcaYJEybYTJjQP4C7/PIIt98eZP9+g/vu8/P8816ee87ghz/0Y5p24nhI50/69WrJX/t8Tk9Uj6e3xYfzde/nzkc7cd3rdVp4BYMBvN7e685r9T6v1xv/k/paPl//10p+ndTXPfj4Dv+YpGb/IiIypikgk1GnqAiKimy+9a0gEKSpCdau9dHcbKSUQft/DpGI0/IjEoGeHoOODifzFo0aiRYf8a9jRz/Gvk697vzxEYnEj4gcvVGPadr9gky/39lE4ff33VzRG8j6fFBQ4PSmKymB0lLn86oq6Oz0pgSoZsrJTXa/06MO9if+mOTAse9zxMec/Hk8EO1/Lfl+9kEfmzxeEZGxQAGZjHrl5XDDDeERfc3KymIaGjoSX1tWPOAjtkbOCdzigaDzuZG4PR74WZaREvClBoBGUoCY/JjUwPBwj+kbZMbHGgw6QWkkQixI7Q1WOzudQLa726C11aCtzaC7Ozl6yR/R73e2GIbdL0hLDdz6ZyZtuzD22NQgsv8f+6D3OfhjBnJ/O21wGf+6d269c+w/73T3O/S1vDwIBvMG/Nh0r3eoxx7+ee0B3S/dOA72GobhzCs/36agwPkY30AUv09JCbS1efu9F8nPke7zg1072O2maVNa6mxaqqy0KC3VLwySSgGZyADEzkJPaoSbbr3c2N6AEAxCW5tBQUER+/d3pA0M438sK/Vr55rTdBgOf9++t8ebEycHoMnBpnPNSHMt+X5GmobHqbf3v5Z6eyBg0t0d7TeH+J901w92397bjAHfP357fEzhsPN9SZ5z/PG9H4001/p/3vda3/t5PBCJmGnuZxz2sQe7Ld04BvIcQ7mW7vUsy6Cnhz6/bKQz8r+AeDx2IvucnC0+WGZ3/HiLY4+1OeooC5+vb7BuH/SXDsNwAtHCQicYjQf1hgGlpb3BaLKDB592v2uHuv9oVlYGLS2pZ/zOnh2lpCQ34wEFZCISEwhAZaXTf66wMP6/3NgOMgerstJHQ0NProeRE05WuCvXw8gKy4Lubidj3N2dGgBXVBRx4EDHYQPAeGDaN6g+3OfJY2hpcXajNzQ4m5niWfR4AA5O4N2XbUN9vcHbb5ts3uwlEun/y0Vv0D7YSOjIyIYPTWpH83/91xDf+EYwR2NRQCYiIkc404TCwuRfNHpVVjprVg9vbPxykpp1doK0YNBZptDV1RtU2jaUlxfS2NiZuJZ8W/K1vrcf7v6HypaOFuPGFdLc3JlybcaM3O7kV0AmIiJyhDCM3vWQcQUFMG6cTd+g0jmNxZ3thEbj3M3D30VEREREskkBmYiIiEiOKSATERERyTEFZCIiIiI5NioCsieffJKLLrqIefPm8eMf/zjXwxEREREZUTnfZVlfX8/q1at57LHH8Pv9XHHFFZxxxhkcf/zxuR6aiIiIyIjIeYZs06ZNnHnmmZSVlVFQUMD8+fOpra3N9bBERERERkzOA7L9+/dTWVmZ+Lqqqor6+vocjkhERERkZOW8ZGlZFoaRfFaanfL14VRUFGVjWP1UVhaPyOuMNm6dN2jubqW5u49b5w2a+2iS84Bs4sSJbN68OfF1Q0MDVVVVA358Y2MHlpXd8xmcM97as/oao5Fb5w2au+buPm6du1vnDZr7SM/dNI1DJpFyXrI866yzeOGFF2hqaqK7u5tnnnmGmpqaXA9LREREZMTkPEM2YcIEbr75Zq699lrC4TCXXXYZp5xyyoAfb5qDPdl+aEbqdUYbt84bNHe30tzdx63zBs19NL2eYduj+Tx2ERERkSNfzkuWIiIiIm6ngExEREQkxxSQiYiIiOSYAjIRERGRHFNAJiIiIpJjCshEREREckwBmYiIiEiOKSATERERyTEFZCIiIiI5poDsEJ588kkuuugi5s2bx49//ONcDyfrrrnmGhYuXMjFF1/MxRdfzMsvv8ymTZtYvHgx8+bNY/Xq1bkeYkZ1dHSwaNEi9uzZA3DQuW7bto0lS5Ywf/58br/9diKRSK6GnDF9537bbbcxb968xHv/61//Gjjy5v7d736XhQsXsnDhQu6++27APe97urm75X3/zne+w0UXXcTChQt56KGHAHe87+nm7Zb3PO4b3/gGt956KzAG3nNb0nrnnXfs8847z25ubrY7OzvtxYsX22+++Wauh5U1lmXZ55xzjh0OhxPXuru77blz59q7du2yw+Gwfd1119nPPfdcDkeZOS+99JK9aNEie/r06fbu3bsPOdeFCxfaf/vb32zbtu3bbrvN/vGPf5zDkQ9f37nbtm0vWrTIrq+v73ffI2nuf/zjH+2PfOQjdjAYtEOhkH3ttdfaTz75pCve93Rzf+aZZ1zxvv/5z3+2r7jiCjscDtvd3d32eeedZ2/btu2If9/Tzfutt95yxXset2nTJvuMM86wv/SlL42Jf+OVITuITZs2ceaZZ1JWVkZBQQHz58+ntrY218PKmrfffhuA6667jg9+8IM88sgjvPLKK0yZMoXJkyfj9XpZvHjxEfM9WLt2LXfccQdVVVUAB51rXV0dPT09zJo1C4AlS5aM+e9B37l3d3ezd+9eli1bxuLFi7n33nuxLOuIm3tlZSW33norfr8fn8/Hcccdx44dO1zxvqeb+969e13xvr/vfe/jf//3f/F6vTQ2NhKNRmlrazvi3/d0887Ly3PFew7Q0tLC6tWrueGGG4Cx8W+8ArKD2L9/P5WVlYmvq6qqqK+vz+GIsqutrY05c+Zw33338aMf/Yif/exn7N2794j9Hnz9619n9uzZia8P9n73vV5ZWTnmvwd9537gwAHOPPNM/vM//5O1a9eyefNmHn300SNu7ieccELiH90dO3bw1FNPYRiGK973dHN///vf74r3HcDn83HvvfeycOFC5syZ45q/733nHYlEXPOer1ixgptvvpmSkhJgbPwbr4DsICzLwjCMxNe2bad8faQ59dRTufvuuykuLqa8vJzLLruMe++91zXfg4O93274OZg8eTL33XcfVVVV5Ofnc80117Bx48Yjdu5vvvkm1113HV/84heZPHmyq9735Lkfe+yxrnrfb7rpJl544QX27dvHjh07XPO+J8/7hRdecMV7/otf/IJJkyYxZ86cxLWx8G+8NyevOgZMnDiRzZs3J75uaGhIlHiORJs3byYcDid+gG3bprq6moaGhsR9juTvwcSJE9POte/1AwcOHHHfg7///e/s2LGD+fPnA8577/V6j8i5b9myhZtuuolly5axcOFC/vKXv7jmfe87d7e872+99RahUIj3vOc95OfnM2/ePGpra/F4PIn7HInve7p5b9iwgbKysiP+Pd+wYQMNDQ1cfPHFtLa20tXVRV1d3ah/z5UhO4izzjqLF154gaamJrq7u3nmmWeoqanJ9bCypr29nbvvvptgMEhHRwe/+tWv+MIXvsD27dvZuXMn0WiU9evXH7Hfg5kzZ6ada3V1NYFAgC1btgCwbt26I+57YNs2//mf/0lrayvhcJif//znfOADHzji5r5v3z4+85nPsGrVKhYuXAi4531PN3e3vO979uxh+fLlhEIhQqEQv/3tb7niiiuO+Pc93bxPP/10V7znDz30EOvXr2fdunXcdNNNnH/++fzgBz8Y9e+5MmQHMWHCBG6++WauvfZawuEwl112Gaecckquh5U15513Hi+//DKXXHIJlmVx1VVXceqpp7Jy5UpuvPFGgsEgc+fOZcGCBbkealYEAoGDznXVqlUsX76cjo4Opk+fzrXXXpvj0WbWtGnTuP7667nyyiuJRCLMmzePRYsWAUfW3B988EGCwSArV65MXLviiitc8b4fbO5ueN/nzp3LK6+8wiWXXILH42HevHksXLiQ8vLyI/p9Tzfvz372s4wbN+6If8/TGQv/xhu2bds5eWURERERAVSyFBEREck5BWQiIiIiOaaATERERCTHFJCJiIiI5JgCMhEREZEcU0AmIiIikmMKyERERERyTAGZiIiISI79fzKz7pW21uUnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index_of_index = [i for i in range(len(X.columns)-1)]\n",
    "\n",
    "sns.lineplot(x=index_of_index, y=in_sample_rmse_by_iteration, color = \"blue\")\n",
    "sns.lineplot(x=index_of_index, y=oos_rmse_by_iteration, color = \"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can kind of see what the optimal model is above. If we want an exact procedure, we'd probably fit a separate smoothing regression to the oos results and analytically find the arg-minimum, $j^*$. That number will then be fed into the model matrix to create the right feature set and the final model will be produced with all the data. Or we can just stop as soon as oos error goes up. You can also obviously do CV within each iterations to stabilize this further (lab exercise).\n",
    "\n",
    "What is the \"optimal model\"?\n",
    "\n",
    "Can we honestly assess future performance now? No... why? Our test set was really our select set and we don't have a third test set (lab exercise). Inner and outer folding can be done too as we discussed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
